{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in d:\\anaconda3\\envs\\whisperx\\lib\\site-packages (from jiwer) (8.1.7)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\whisperx\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n",
      "Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.6 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.5 rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "#!pip install jiwer\n",
    "from jiwer import wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "audio_file = \"data/1min_sample.wav\" # path to audio file\n",
    "text_file = \"data/1min_sample.txt\" # path to text file\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transcribe with original whisper (batched)\n",
    "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, language=\"en\") # load model with English language\n",
    "\n",
    "# save model to local path (optional)\n",
    "# model_dir = \"/path/\"\n",
    "# model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)\n",
    "audio = whisperx.load_audio(audio_file)\n",
    "result = model.transcribe(audio, batch_size=batch_size)\n",
    "print(result[\"segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good afternoon. My colleagues and I remain squarely focused on achieving our dual mandate goals of maximum employment and stable prices for the benefit of the American people. Our economy is strong overall and has made significant progress toward our goals over the past two years. The labor market has cooled from its formerly overheated state. Inflation has eased substantially from a peak of 7% to an estimated 2.2% as of August. We're committed to maintaining our economy's strength by supporting maximum employment and returning inflation to our 2% goal. Today, the Federal Open Market Committee decided to reduce the degree of policy restraint by lowering our policy interest rate by a half percentage point.\n",
      "Good afternoon. My colleagues and I remain squarely focused on achieving our dual-mandate goals of maximum employment and stable prices for the benefit of the American people. Our economy is strong overall and has made significant progress toward our goals over the past two years. The labor market has cooled from its formerly overheated state. Inflation has eased substantially from a peak of 7 percent to an estimated 2.2 percent as of August. We’re committed to maintaining our economy’s strength by supporting maximum employment and returning inflation to our 2 percent goal. Today, the Federal Open Market Committee decided to reduce the degree of policy restraint by lowering our policy interest rate by ½ percentage point.\n",
      "Word Error Rate (WER): 0.07964601769911504\n",
      "Character Error Rate (CER): 0.045205479452054796\n"
     ]
    }
   ],
   "source": [
    "transcription = \"\".join([i[\"text\"] for i in result[\"segments\"]])[1:]\n",
    "\n",
    "\n",
    "with open(\"data/1min_sample.txt\", \"r\") as file:\n",
    "    reference_transcription = file.read().replace(\"\\n\", \" \")\n",
    "\n",
    "print(transcription) # before alignment\n",
    "print(reference_transcription)\n",
    "\n",
    "\n",
    "# Calculate Word Error Rate (WER)\n",
    "word_error_rate = wer(reference_transcription, transcription)\n",
    "print(f\"Word Error Rate (WER): {word_error_rate}\")\n",
    "\n",
    "# Calculate Character Error Rate (CER)\n",
    "character_error_rate = cer(reference_transcription, transcription)\n",
    "print(f\"Character Error Rate (CER): {character_error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete model if low on GPU resources\n",
    "# import gc; gc.collect(); torch.cuda.empty_cache(); del model\n",
    "\n",
    "# 2. Align whisper output\n",
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "\n",
    "print(result[\"segments\"]) # after alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete model if low on GPU resources\n",
    "# import gc; gc.collect(); torch.cuda.empty_cache(); del model_a\n",
    "\n",
    "# 3. Assign speaker labels\n",
    "diarize_model = whisperx.DiarizationPipeline(use_auth_token=YOUR_HF_TOKEN, device=device)\n",
    "\n",
    "# add min/max number of speakers if known\n",
    "diarize_segments = diarize_model(audio)\n",
    "# diarize_model(audio, min_speakers=min_speakers, max_speakers=max_speakers)\n",
    "\n",
    "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
    "print(diarize_segments)\n",
    "print(result[\"segments\"]) # segments are now assigned speaker IDs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
