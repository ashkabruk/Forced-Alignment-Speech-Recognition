{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\whisperx\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "d:\\anaconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n",
      "INFO:datasets:PyTorch version 2.0.0 available.\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "#!pip install jiwer\n",
    "from jiwer import wer, cer\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from peft import PeftModel, LoraConfig\n",
    "import time\n",
    "import evaluate\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from IPython.display import Audio\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    # Remove punctuation except apostrophes\n",
    "    text = re.sub(r'[{}]+'.format(re.escape(string.punctuation.replace(\"'\", \"\"))), ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_metrics(pred_str, label_str):\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Converting finetuned Whisper to WhisperX support)\n",
    "not needed since WhisperX cannot load weights from fine-tuned model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json recreated and saved to output_dir/checkpoint-903/config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define paths to your existing files\n",
    "adapter_config_path = \"output_dir/checkpoint-903/adapter_config.json\"\n",
    "preprocessor_config_path = \"output_dir/checkpoint-903/preprocessor_config.json\"\n",
    "tokenizer_config_path = \"output_dir/checkpoint-903/tokenizer_config.json\"\n",
    "output_config_path = \"output_dir/checkpoint-903/config.json\"\n",
    "\n",
    "# Load the existing files\n",
    "with open(adapter_config_path, \"r\") as f:\n",
    "    adapter_config = json.load(f)\n",
    "\n",
    "with open(preprocessor_config_path, \"r\") as f:\n",
    "    preprocessor_config = json.load(f)\n",
    "\n",
    "with open(tokenizer_config_path, \"r\") as f:\n",
    "    tokenizer_config = json.load(f)\n",
    "\n",
    "# Combine into the final config.json structure\n",
    "config = {\n",
    "    \"_name_or_path\": \"openai/whisper-small\",\n",
    "    \"architectures\": [\"WhisperForConditionalGeneration\"],\n",
    "    \"d_model\": 512,\n",
    "    \"decoder_attention_heads\": 8,\n",
    "    \"decoder_ffn_dim\": 2048,\n",
    "    \"decoder_layers\": 6,\n",
    "    \"encoder_attention_heads\": 8,\n",
    "    \"encoder_ffn_dim\": 2048,\n",
    "    \"encoder_layers\": 6,\n",
    "    \"model_type\": \"whisper\",\n",
    "    \"use_cache\": True,\n",
    "    \"task_specific_params\": {\n",
    "        \"transcribe\": {\"max_length\": 448},\n",
    "        \"translate\": {\"max_length\": 512}\n",
    "    },\n",
    "    \"vocab_size\": 51864,\n",
    "    \"num_hidden_layers\": 6,\n",
    "    \"tie_word_embeddings\": False,\n",
    "    \"adapter_config\": adapter_config,\n",
    "    \"preprocessor_config\": preprocessor_config,\n",
    "    \"tokenizer_config\": tokenizer_config\n",
    "}\n",
    "\n",
    "# Save the config.json file\n",
    "with open(output_config_path, \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"config.json recreated and saved to {output_config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json created at output_dir/checkpoint-903\\config.json\n",
      "Model conversion complete.\n",
      "config.json created at output_dir/checkpoint-903\\config.json\n",
      "Model conversion complete.\n"
     ]
    }
   ],
   "source": [
    "# we need to get tokenizer_config.json and merges.txt\n",
    "!wget -O output_dir/checkpoint-903/merges.txt https://huggingface.co/openai/whisper-small/blob/main/tokenizer_config.json\n",
    "!wget -O output_dir/checkpoint-903/merges.txt https://huggingface.co/openai/whisper-small/resolve/main/merges.txt\n",
    "\n",
    "# transfor model to whisperx\n",
    "!ct2-transformers-converter --model output_dir/checkpoint-903 --output_dir output_dir/whisperx --quantization float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whisper_model():\n",
    "    whisper_model_name = \"openai/whisper-small\"\n",
    "    whisper_model = WhisperForConditionalGeneration.from_pretrained(whisper_model_name)\n",
    "    whisper_processor = WhisperProcessor.from_pretrained(whisper_model_name, language=\"en\", task=\"transcribe\")\n",
    "    return whisper_model, whisper_processor\n",
    "\n",
    "# Load the fine-tuned Whisper model\n",
    "def load_fine_tuned_model():\n",
    "    whisper_model_name = \"openai/whisper-small\"\n",
    "    adapter_path = \"ashkab/whisper_fine-tuned\"\n",
    "    config = LoraConfig(r=32, lora_alpha=64, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.5, bias=\"none\")\n",
    "    base_model = WhisperForConditionalGeneration.from_pretrained(whisper_model_name)\n",
    "    fine_tuned_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    fine_tuned_processor = WhisperProcessor.from_pretrained(whisper_model_name, language=\"en\", task=\"transcribe\")\n",
    "    return fine_tuned_model, fine_tuned_processor\n",
    "\n",
    "# Load WhisperX model\n",
    "def load_whisperx_model(device, compute_type):\n",
    "    return whisperx.load_model(\"small\", device, compute_type=compute_type, language=\"en\")\n",
    "\n",
    "\n",
    "def load_fine_tuned_whisperx_model(device, compute_type, fine_tuned_model_dir):\n",
    "    \"\"\"\n",
    "    Load WhisperX with a fine-tuned CTranslate2 Whisper model.\n",
    "    \"\"\"\n",
    "    # Load the base WhisperX model\n",
    "    whisperx_model = whisperx.load_model(\"small\", device, compute_type=compute_type, language=\"en\")\n",
    "\n",
    "    # Ensure the model is loaded as a CTranslate2 translator\n",
    "    from ctranslate2 import Translator\n",
    "    translator = Translator(fine_tuned_model_dir, device=device)\n",
    "\n",
    "    # Replace the WhisperX encoder with the fine-tuned translator\n",
    "    whisperx_model.hf_encoder = translator\n",
    "\n",
    "    return whisperx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe with Whisper or fine-tuned Whisper\n",
    "def transcribe_with_model(model, processor, audio_path, chunk_size=30):\n",
    "    \"\"\"\n",
    "    Transcribe audio using the specified model and processor, supporting audio longer than chunk_size seconds.\n",
    "    \"\"\"\n",
    "    audio_input, sample_rate = sf.read(audio_path)\n",
    "    chunk_samples = int(chunk_size * sample_rate)\n",
    "    transcriptions = []\n",
    "    for start_sample in range(0, len(audio_input), chunk_samples):\n",
    "        end_sample = start_sample + chunk_samples\n",
    "        audio_chunk = audio_input[start_sample:end_sample]\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_chunk, sampling_rate=sample_rate, return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(input_features)\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        transcriptions.append(transcription)\n",
    "    return \" \".join(transcriptions)\n",
    "\n",
    "# Transcribe with WhisperX\n",
    "def transcribe_with_whisperx(whisperx_model, audio_path, batch_size=16):\n",
    "    audio = whisperx.load_audio(audio_path)\n",
    "    result = whisperx_model.transcribe(audio, batch_size=batch_size)\n",
    "    return result[\"segments\"]\n",
    "\n",
    "# Separate transcription functions for each model\n",
    "def transcribe_with_base_whisper(audio_path):\n",
    "    whisper_model, whisper_processor = load_whisper_model()\n",
    "    print(\"Transcribing with base Whisper model...\")\n",
    "    start_time = time.time()\n",
    "    transcription = transcribe_with_model(whisper_model, whisper_processor, audio_path)\n",
    "    time_needed = time.time() - start_time\n",
    "    print(f\"Base Whisper transcription completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return transcription, time_needed\n",
    "\n",
    "def transcribe_with_fine_tuned_whisper(audio_path):\n",
    "    fine_tuned_model, fine_tuned_processor = load_fine_tuned_model()\n",
    "    print(\"Transcribing with fine-tuned Whisper model...\")\n",
    "    start_time = time.time()\n",
    "    transcription = transcribe_with_model(fine_tuned_model, fine_tuned_processor, audio_path)\n",
    "    time_needed = time.time() - start_time\n",
    "    print(f\"Fine-tuned Whisper transcription completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return transcription, time_needed\n",
    "\n",
    "def transcribe_with_whisperx_model(audio_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "    whisperx_model = load_whisperx_model(device, compute_type)\n",
    "    print(\"Transcribing with WhisperX model...\")\n",
    "    start_time = time.time()\n",
    "    transcription = transcribe_with_whisperx(whisperx_model, audio_path)\n",
    "    time_needed = time.time() - start_time\n",
    "    print(f\"WhisperX transcription completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return transcription, time_needed\n",
    "\n",
    "def transcribe_with_fine_tuned_whisperx(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribe audio using the fine-tuned WhisperX model.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "\n",
    "    # Specify the directory of the transformed fine-tuned model\n",
    "    fine_tuned_model_dir = \"output_dir/checkpoint-903\"  # Directory where the transformed model is saved\n",
    "\n",
    "    # Load the fine-tuned WhisperX model\n",
    "    fine_tuned_whisperx_model = load_fine_tuned_whisperx_model(device, compute_type, fine_tuned_model_dir)\n",
    "\n",
    "    print(\"Transcribing with fine-tuned WhisperX model...\")\n",
    "    start_time = time.time()\n",
    "    transcription = transcribe_with_whisperx(fine_tuned_whisperx_model, audio_path)\n",
    "    time_needed = time.time() - start_time\n",
    "    print(f\"Fine-tuned WhisperX transcription completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    return transcription, time_needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on long audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify on what you rather want to test - short or long\n",
    "audio_file = \"data/audio_files/20190130_FOMC.wav\" # path to audio file\n",
    "text_file = \"data/transcript_files/20190130_FOMC.txt\" # path to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True transcription:\n",
      " Good afternoon, everyone, and welcome. I will start with a recap of our discussions, including our assessment of the outlook for the economy and the judgments we made about our interest rate policy and our balance sheet. I will cover the decisions we made today as well as our ongoing discussions of matters on which we expect to make decisions in coming meetings. My colleagues and I have one overarching goal: to sustain the economic expansion, with a strong job market and stable prices, for the benefit of the American people. The U. economy is in a good place, and we will continue to use our monetary policy tools to help keep it there. The jobs picture continues to be strong, with the unemployment rate near historic lows and with stronger wage gains. Inflation remains near our 2 percent goal. We continue to expect that the American economy will grow at a solid pace in 2019, although likely slower than the very strong pace of 2018. We believe that our current policy stance is appropriate at this time. Despite this positive outlook, over the past few months we have seen some crosscurrents and conflicting signals about the outlook. Growth has slowed in some major foreign economies, particularly in China and Europe. There is elevated uncertainty around several unresolved government policy iss ues, including Brexit, ongoing trade negotiations, and the effects from the partial government shutdown in the United States. Financial conditions tightened considerably late in 2018 and remain less supportive of growth than they were earlier in 2018. An d, while most of the incoming domestic economic data have been solid, some surveys of business and consumer sentiment have moved lower, giving reason for caution. We always emphasize that our policies are data dependent. In other words, as economic condit ions and the outlook evolve, we take that new information into account in setting our policies. We are now facing a somewhat contradictory picture of generally strong U. macroeconomic performance alongside growing evidence of crosscurrents. At such times, common- sense risk management suggests patiently awaiting greater clarity—an approach that has served policymakers well in the past. With that in mind, I’d like to spell out how the Federal Open Market Committee has been thinking about these issues. At our December meeting, we noted the solid outlook for steady growth, vigorous job creation, and price stability. We also stressed that the extent and timing of any rate increases were uncertain and would depend on incoming data and the evolving outlook. We therefore said that we would be paying close attention to global economic and financial developments and assessing their implications for the economic outlook. Today the FOMC decided that the cumulative effects of those developments over the last several months warrant a patient, wait- and-see approach regarding future policy changes. In particular, our statement today says,“In light of global economic and financial developments and muted inflation pressures, the Committee will be patient as it determin es what future adjustments to the target range for the federal funds rate may be appropriate.” This change was not driven by a major shift in the baseline outlook for the economy. Like many forecasters, we still see“sustained expansion of economic activi ty, strong labor market conditions, and inflation near... 2 percent” as the likeliest case. But the crosscurrents I mentioned suggest the risk of a less favorable outlook. In addition, the case for raising rates has weakened somewhat. The traditional case for rate increases is to protect the economy from risks that arise when rates are too low for too long, particularly the risk of too- high inflation. Over the past few months, that risk appears to have diminished. Inflation readings have been muted, and the recent drop in oil prices is likely to push headline inflation lower still in coming months. Further, as we noted in our postmeeting statement, while survey-based measures of inflation expectations have been stable, financial market measures of i nflation compensation have moved lower. Similarly, the balance—the risk of financial imbalances appears to have receded, as a number of indicators that showed elevated levels of financial risk appetite last fall have moved closer to historical norms. In this environment, we believe we can best support the economy by being patient in evaluating the outlook before making any future adjustment to policy. Let me now turn to balance sheet normalization. Over its past three meetings, the FOMC has held in- depth discussions on the final stages of this process. Today we made some important progress in clarifying the path forward, as summarized in the Statement Regarding Monetary Policy Implementation and Balance Sheet Normalization that we released with today’s statement. The Committee made the fundamental decision today to continue indefinitely using our current operating procedure for implementing monetary policy. That is, we will continue to use our administered rates to control the policy rate with an am ple supply of reserves so that active management of reserves is not required. This is often called a“floor system” or an“abundant reserves system.” Under the current set of operating procedures, as outlined in the implementation note released today, th is means that the federal funds rate, our active policy tool, is held within its target range by appropriately setting the Federal Reserve’s administered rates of interest on reserves, as well as the offer rate on the overnight reverse repo facility, without managing the supply of reserves actively. As the minutes of our recent discussions have indicated, the FOMC strongly believes that this approach provides good control of short-term money market rates in a variety of market conditions and effective tran smission of those rates to broader financial conditions. Settling this central question clears the way for the FOMC to address a number of further questions regarding the remaining stages of balance sheet normalization. The decision to retain our current operating procedure means that, after allowing for currency in circulation, the ultimate size of our balance sheet will be driven principally by financial institutions’ demand for reserves, plus a buffer so that fluctuations in reserve demand do not requir e us to make frequent sizable market interventions. Estimates of the level of reserve demand are quite uncertain, but we know that this demand in the post-crisis environment is far larger than before. Higher reserve holdings are an important part of the stronger liquidity position that financial institutions must now hold. Moreover, based on surveys and market intelligence, current estimates of reserve demand are considerably higher than estimates of a year or so ago. The implication is that the normali zation of the size of the portfolio will be completed sooner, and with a larger balance sheet, than in previous estimates. In light of these estimates and the substantial progress we have made in reducing reserves, the Committee is now evaluating the appro priate timing for the end of balance sheet runoff. This decision will likely be part of a plan for gradually reaching our ultimate balance sheet goals while minimizing risks to achieving our dual- mandate objectives and avoiding unnecessary market disrupti on. We will be finalizing these plans at coming meetings. The process of balance sheet normalization is unprecedented. Throughout this process we’ve attempted to lay out our plans well in advance, and we’ve been willing to make changes as we learn more about the process. The implementation and normalization statement released today is intended to provide some additional clarity regarding the conditions under which we might adjust our plans. The statement makes three points: First, as we’ve long emphasi zed, the federal funds rate is our active monetary policy tool. Second, as far as the particular details of normalization are concerned, we will not hesitate to make changes in light of economic and financial developments. This does not mean that we would use the balance sheet as an active tool, but occasional changes could be warranted. Third, we repeat a sentence of the normalization principles we adopted in June of 2017. While the federal funds rate would remain our acti ve tool of policy in a wide range of scenarios, we recognize that the economy could again present conditions in which federal funds rate policy is not sufficient. In those cases, the FOMC would be prepared to use its full range of tools, including balance sheet policy. Times of economic uncertainty put a premium on the clarity and predictability of FOMC policy. We are committed to clearly explaining what we are doing and why we’re doing it, both regarding the path of rates and also regarding management of the balance sheet. We believe that this transparency is how we can best contribute to macroeconomic stability. Thank you. I’ll be glad to take your questions. Howard Schneider with Reuters. So you’ ve said many times recently that policy was still accommodative and that it needn’t be so. You’ve said recently that policy—the state of the policy was still accommodative and that the economy didn’ t require that anymore. Is that still the case? If so, how do you justify the removal of the need for some further interest rate increases? Basically, are we at neutral now, or does the economy still need accommodation. We think that our policy is at the appropriate point right now. We think our policy stance is appropriat e right now. We do. We also know that our policy rate is now in the range of the Committee’s estimates of neutral. So we’ll be—again, we think our policy stance is appropriate. Heather Long from the Washington Post. Last week, the IMF said risks are clearly skewed to the downside for the U. and global economy. Can you clarify— does the FOMC see risks as skewed to the downside, particularly after you removed the statement about risk s being balanced. We had an extensive discussion of the baseline and also of the risks to the baseline, and the risks are, of course, the fact that financial conditions have tightened, that global growth has slowed, as well as some, let’s say, government-related risks like Brexit and trade discussions, and also the effects and ultimate disposition of the shutdown. So we looked at—we look at those, and the way we think of it is that policy—we will use our policy, and we have, to offset risks to the baseline. So we view the baseline as still solid, and part of that is the way we adjusted our baseline to address those risks. So that’s the way we’re thinking about that now. Thanks. Sam Fleming from the Financial Times. The Fed has linked its commitment to patie nce in part to subdued inflation outcomes. Would you be comfortable with continuing patience even if there are modest, if transient, overshoots to the inflation target by core inflation? How sensitive are you right now to developments in core inflation w hen determining the next move? Thanks. You know, generally speaking, we think the outlook is favorable, and we think that these crosscurrents that I referred to—these risks—are going to be with us for a while. We think our stance is appropriate. We think there’s no pressing need to change our policy stance and no need to rush to judgment there. I would say that we’ll be looking at a full range of data, and that will include inflation data. It will include all data relevant to our dual mandate of stable prices and maximum employment. Remember that our inflation objective is a symmetric one, meaning that we are— we’re always trying to get to 2 percent, and we don’ t look at—we look at inflatio n equally on both sides. So I can’t get into specific hypotheticals, but I do believe that we have a symmetric objective, and I believe we’ ll act that way. We learned from the last minutes of the meeting that some of the tweaks you make t o the statement have a lot more portent than we thought. In light of that, I’m wondering if you can provide us with a“ decoder ring” for this statement.“ Adjustments”—does that suggest the next move in interest rates is as likely to be up as down? And w hen you twin“ in light of global economic and financial developments” with“ muted inflation pressures,” does that suggest you have to see both the cessation of these crosscurrents that you’ ve talked about and inflation moving up before you get off the dime, so to speak, and move. Sorry—say again what the first question was. First question is,“ adjustments”—is that meant to imply the next move is as most likely to be up as down. Ye s. I’m just going to say that the—it’ s going to depend entirely on the data. We’re not making a judgment. We don’ t have a strong prior. We will be— we will patiently wait and let the data clarify. Some of the crosscurrents that I refer to may be with us for a while, and I think we’ll be looking at seeing those clear up as it relates to—as they relate to the outlook for the U.S. and that will be an important aspect as well. Your second question was?. Would it be not just the cessation of those crosscurrents, but the end of these muted inflation pressures—are they both sort of things that are necessary for you to change this“ patient” stance. You know, it’s really hard to speak about generalities. We’ll be looking at everything, but I do think that, you know, muted inflation pressures—you know, you would want—I would want to see a need for further rate increases, and, for me, a big part of that would be inflation. It wouldn’ t be the only thing, but it would certainly be importa nt. Steve Liesman, CNBC. Mr. Chairman, did the Committee discuss an actual change to the runoff policy or the runoff schedule right now? If so, is that under consideration right now, and when might we know? The second thing is, I have to nail down this thing. You guys, Fed folks, keep mentioning the“market average” or the“market outlook” for the size of the balance sheet. Are you endorsing the market average, which is 3 ½ trillion? And if you’re not endorsing it, why do you keep mentioning it. Okay. So today I’m here to talk about decisions and also discussions about decisions that haven’ t been made. So we’re talking about the latter thing, which is discussions, and so I can’t get ahead of where decisions are. But so the Committee is— what we’re looking to do is create a whole plan that will bring us to our goal, our longer-run goal, which is a balance sheet no larger than it needs to be for us to efficiently conduct— efficiently and effectively conduct monetary policy, but to do so in a way that doesn’ t put our goals at risk or result in unnecessary market turmoil. So there are a lot of pieces to that, and we’ve learned over time that it’s—when making these—when designing these plans, like, for example, the original normalization plan, it’ s good to take your time. Let the best ideas rise to the top. Let them stand the test of time and argument and then move when you’ re really comfortable with what you’ve got and when you feel you can communicate it clearly. So I don’ t want to get ahead of that process today. But—so we’ve discussed—there are a number of pieces to that puzzle. There are several different pieces to them, and I think they’re coming—and I’m very pleased with the progress that we’ve made, and, you know, the piece that you mentioned is something that is in those discussions. That’s the first question. I’m not going to give our estimate or ratify anybody else’s estimate of what the equilibrium balance sheet is here today. There are estimates out there, but I’m not at a point today where I’m going to be giving out numbers on that. But there are estimates, and I think they’re consistent with what I said, broadly speaking. So, just to clarify—I’m sorry, you did discuss reducing the pace of the runoff? That sounds like what you said, to me.. Yes, it’s—so, a gain, we haven’ t made any decisions. There n o decisions have been made. There are different pieces of the thing, and that is in the discussion as one of many pieces that is in the discussion. A nd that was reflected in the last minutes, actually. Thanks. Nick Timiraos of the Wall Street Journal. Chairman Powell, I want to follow up on Steve’s question. The size of the balance sheet obviously matters a great deal, but, so, too, if you follow the arguments that were made when the Fed was purchasing these assets, does the duration of those holdings. So once you are—once you reach the terminal level of reserves and you have to reinvest maturing mortgage-backed securities into Treasuries, it will matter a great deal, of course, where along the curve the Fed resumes those reinvestments. And so I wonder, what does your staff research show about the degree of accommodation that would be provided by either moving to the front end of the curve and holding or investing, perhaps, in shorter maturity assets, versus the other approach that was identified in the December meeting minutes, which would be to si mply reflect issuance of the outstanding Treasury maturities? And which approach do you think is more a ppropriate in the current environment. These are great questions. Let me say that the question of the ultimate composition of our balance sheet in the longer run is a very important one, and it’s one that we see ourselves as coming to, you know, fairly soon, as in, in coming meetings. It won’t be the first thing we work on, but it will be one of the first things that we try to resolve. We had discussions at one of the last two meetings on this, and we haven’t come to a judgment on that. And, you know, I wouldn’ t comment beyond saying that we understand that’s a key question, and there are, you know, there are issues to be decided. There are benefits and costs to doing— to taking different approaches, and I wouldn’ t want to prejudge them today. Binya Appelbaum, New York Times. I am struggling a little bit to understand what has changed since we sat here with you six weeks ago. You’ve said today that you think that inflation would be the reason that the Fed would need to continue raising rates. Has the inflation outlook shifted that dramatically in the last six weeks? Can you speak specifically to why you’ve mo ved from a posture of saying we expect to keep raising rates this year to a posture of standing still. I’d point to a couple of things. First, the narrative of slowing global growth continues, if you will. The incoming data have shown more of that. We’ve seen that both in China and in Western Europe, and so that’s an important—that has important implications for us, and that story has—let’s just say it continues. And, in addition— I mean, I think important—possibly less important now—probably less important now, but—has been the shutdown, which will leave some sort of imprint on first- quarter GDP. We don’ t know the ultimate resolution of it. If that’s all there is, and the shutdown is gone and there isn’ t another shutdown, then we’ll get most of that back in the second period—second quarter. So those things—in addition, you know, you have to look back. Financial conditions began to tighten in the fourth quarter. And they now have persisted and remain tight er— significantly tighter, let’s say—than they were, and that’s something that we have to take into account as well. So that’s where we are. Michael McKee from Bloomberg Television and Radio. You said you like to be a plain speaker, so let me try to have you put this as plainly as possible. Is it fair to characterize this as not a pause in a tightening cycle, but the end of the tightening cycle now—a new regime for the Fed? And, if not, can you put a time frame on“patient”? Does“ patient” have some sort of time frame? And I’m wondering about your reaction to the criticism you got on your December 19th news conference, your later statements—do you feel you’ve put a“Powell put” into the markets. So, patience— I think we’re going to know in hindsight, because the length of this patient period is going to depend entirely on incoming data and its implications for the outlook. So that’s going to be—so it’ s hard to say, you know, it’ s hard to think of what to call it a t this point or how to label it. So really, your second question is about how do we think about financial conditions. And I would say this: We think about a broad range of financial conditions, not just one or two things. You know, it’ s interest rates, it’ s risk spreads, it’ s currency, it’ s the stock market, it’ s credit availability, it’ s many, many factors. And what matters for financial conditions is, when there are changes and those changes are sustained for a period of time, then they become importa nt for us because they have important macroeconomic implications. So that’s how we think about it. So we don’ t react to, you know, to most things that happen in the financial markets. But when we see a sustained change in financial conditions, then that’s something that has to play into our thinking. In fact, our policy works through changing financial conditions, so it’ s sort of the essence of what we do. Victoria Guida with Politico. I just wanted to ask, first of all, about whether t he Fed is gathering information about some of the new money laundering information that’s come out about Deutsche Bank and Danske Bank and whether you have any concerns there? And then, also, I was just wondering if you could say whether there’ s any kind of timeline on when the Fed might make a decision on real-time payments and whether you’re going to build a real-time payment system. Right. So, on the first question, I can—we don’ t comment on individual investigations or whether they’re happening. I will say that we take our enforcement powers very seriously, and we put them to work when we feel it’ s justified. In terms of real-time payments, it’ s something we’re very actively working on. As you obviously know, we have some proposals out, and we’re considering them. You know, the thing is, it’s very important in that space to consult with the full range of market participants and interest groups, consumer groups, and we’ve done that, as I’m sure you know, over a period of years. We don’ t have plenary authority to just do things, for the most part, in the payment space. We’ve been more of a convener, bringing industry and the public—public interest groups—and all those groups around the table. And we’ve— I think we’ve played a constructive role in that respect, and I believe that will continue.. Thanks. Jim Puzzanghera with the L. Times. You and your colleagues may have noticed, President Trump, for the past six months, has been urging the Fed not to raise r ates—to stop raising rates. How would you respond to those who would suggest that the Fed just caved to the president’s demands. So what we care about—and, really, the only thing we care about at the Fed—is doing our job for the American people and using our tools appropriately. So that’s very strongly our culture. I think anyone who knows the Fed or who has worked at the Fed would recognize that description. So we’re always going to do what we think is the right thing. We’re never go ing to take political considerations into account or discuss them as part of our work. You know, we’re human. We make mistakes. But we’re not going to make mistakes of character or integrity. And I would want the public to know that, and I would want them to see that in our actions. Edward Lawrence from Fox Business News. Thank you, Mr. Chairman. The long-term federal funds rate is 2.8 percent. I’ve talked the last year with a number of Fed presidents who worry that under 3 percent is not enough to handle the next recession. You say that’s your first tool, that’s your primary means of adjusting monetary policy. So with a larger balance sheet—with a larger balance sheet, could you—how could you handle that next re cession, then, with the combination of those two. I guess the sense of your question is that we could be in a situation in the future—we hope not, but—we could be in a situation where we’d like to cut rates more than we can effectively, and we hit the zero lower bound. We don’ t think anything like that is in the cards. Now, there’ s no reason to think that it would be. But as we said in today’s release, if that happens, then we’ll use the full range of our tools, and that includes the balance sheet. But we would use it after using our conventional tools, which would be the interest rate and forward guidance about the interest rate. Even if you have a large balance sheet—$4 trillion? Above$4 trillion. Yes. There would be room to do substantially more. Chairman Powell, Donna Borak with CNN. I just wanted to go back to—you had mentioned on the crosscurrents, the government shutdown issue. You mentioned a couple of weeks ago that that information would clearly show up in the data. I’m wondering, as you guys discussed during this week’s meeting, what the potential economic impact would be of the shutdown, the possibility of a second one, whether or not it would dim inish consumer confidence, have some severe ripple effects? Just talking to other folks outside, businesses— clearly they were suffering and seeing a lot of pain. I’m just wondering about, for American families that missed two paychecks, how is this going to play out for them for the months to come. Right. So let me give you the economic side of it first—is that, even with a fairly long shutdown, as long as that’s the end of it and everyone gets their backpay—except the contractors, I guess, the private- sector contractors, but—some people get their backpay, then the lost GDP will be regained in the second quarter. So that’s that. I would say that the—you know, we all see the suffering and the heartbreak and all the pain people go through. I see, you know, federal employees doing their work, and I’m, you know, really grateful they did. I mean, to be doing your work while you’re not getting paid, it’s something we should all be grateful for. Did that answer both your questions?. Yes, it does. So you don’t see a permanent effect of this shutdown? And I’m just wondering if you’re thinking about the path of future policy and the possibility of reaching this point again on February 15. So would there be a p ermanent effect? As I mentioned, there wouldn’ t be if there isn’t another shutdown. If there were going to be a permanent effect or a lasting effect, let’s say, it would be from a longer shutdown or perhaps a second shutdown, and that would be through the channel of a loss of confidence in our ability to make policy in the United States. That would be the channel. And I think that was something that we and many others were worried about as there was talk of an even longer shutdown. In terms of ideas for not having more shutdowns, I know Congress is actually looking at some of those, so I think that could be a profitable thing to explore. Marty Crutsinger, AP. The Beige Book that was prepared for this mee ting noted a rising concern among business contacts about higher trade tariffs and the tensions there. Did that play a part in the discussion and the decision that you made on shifting the wording i n your statement. So, trade— you sound l ike you’re an avid reader of the Beige Book, and that’s great—the trade, as you will know, then—trade has been a big feature in the Beige Book for some time now. The Beige Book is a collection of all of our—of the comments that our Reserve Bank presidents get from their Districts. It’s incredibly valuable, because you’re getting actual reports from people who are on the line. And there have been real concerns about trade right along the line, both in terms of availability of materials and costs and retal iation and that kind of thing. So that’s been a concern. I would say the longer-term concern, though, is the negotiations that are going on. If they linger, then there could be more and more uncertainty, and you worry over time that that could have an effect on business confidence. So far, the actual amount of tariffs that have been applied both here and in China is not enough to have material effects on GDP either here or in China. So the concern is more a longer—for me—a longer, drawn-out set of negotiations back and forth, which could result in sapping business confidence. Uncertainty is not the friend of business.-GENZER. I’m Nancy Marshall-Genzer from Marketplace. I want to talk to you about corporate debt. Are you worried that by taking a pause in raising interest rates—we’ve had low interest rates for so long—are you contributing to a bubble in corporate debt. So, we did—we’ve called out corporate debt as a risk—more of a macroeconomic risk, I think, than a financial stability risk, t he sense of that being that if you have companies that are highly levered and we do go into a downturn, they’re going to be less able to weather that and keep serving their customers and, you know, may have to do layoffs and things like that. So they can amplify, in effect, a negative downturn. So we watch that. We also watch carefully for the exposure of the financial system to these companies. In other words, banks are arranging a lot of these loans. The question is, what is their exposure? Do they retain big pieces of the loans? Do they have obligations to underwrite loans which build up in a pipeline? So we monitor those risks very carefully. And, frankly, the banks monitor them much better with our support and help than they did before the crisis. So it’ s a concern. It’s something that we’re watching. Of course, you know, November, December, and January were much slower months for those sorts of things. But, you know, it’ ll be something that we’re always paying close attention to.. Chairman Powell, Greg Robb from MarketWatch. Financial markets have reacted strongly to the decision and the press conference. The Dow Jones i ndustrial average is up more than, like, 500 points. There’ s a sense in the market that there’ s, you know, what people call the“ Powell put” on the markets. Are financial markets wrong in that assessment. You know, I would point to all the continuity here. You know, the thing we did on the balance sheet is something we’ve been working on for, frankly, years— the thing we announced today. And so we’re providing clarity there. I think that’s a constructive thing to do. My—honestly—only motivation is to do the right thing for the economy and for the American people—that’s it. And this situation, I think, calls for patience—I think it does. And it’s just the stance of policy we think is appropriate. We see these uncertainties, and we see a time wh en we can afford to—we have the luxury of being able to wait and watch, and that’s what we’re planning to do. And I think it’ s the right thing. I feel strongly that it is. Chairman Powell, the Office of the Comptroller of the Currency last year completed its f intech c harter. And one of the questions around that charter has been whether the Federal Reserve will allow such a chartered bank to access the payment system. I’m curious if you think a f intech c harter is a good idea in general, and what conditions you think might be necessary to allow the Fed to allow such a chartered institution access to the payment system. I’m not going to be able to help you much on that. Those are great questions, and those are questions that are, you know, that our great supervisory people are looking at. I think we’re open to these ideas, but I don’ t have any news for you on that today.. Thank you. Steve Beckner, freelance journalist reporting for NPR. Mr. Chairman, you’ve echoed the widespread concern about slowing growth in China and elsewhere in the world, but I wonder whether it’ s possible that slower growth abroad might actually be beneficial to this country, in some respects, at least—for example, perhaps increasin g capital inflows and putting downward pressure on long-term rates in this country, as happened in the Asian financial crisis in the late’90s. You know, Steve, it’ s certainly possible. Ultimately, though, you know, a strong global economy is good for us. We export to these countries. We trade with these countries. I mean, part of the story of 2017, for example, was that European growth kept coming in stronger and stronger, and that meant the euro was strong, and that supported our exports. So, ultimately, I think we benefit from having strong growth abroad, although you point to an interesting case. Chairman Powell, Mark Hamrick with Bankrate. Thank you. As you probably heard, the Congressional Budget Office is projecting that federal debt is expected to surge to about$29 trillion over the next 10 years, reaching the highest share since the end of World War II. First of all, does that sound like it could be a reasonable forecast, with the Administration seeming to take plenty of opportunities to question the legitimacy of CBO? And then, secondly, what effect does that have on interest rates and the public if indeed that’s even close to being true. So, first, it is important—we don’ t do fiscal policy. We don’ t advise the government or Congress on fiscal policy, so I’ll limit myself to more high-level comments and say that it is not a secret—it is a long-known fact that the U. federal g overnment budget is on an unsustainable path, and that needs to be addressed. And that is driven principally by the combination of health- care costs—really, due to our health- care delivery system—and the aging of the population. And there’ s no time like now—when the economy is healthy, growing, people are working—to go after that problem. Ultimately, we will have to. We don’ t have a forecast. We don’ t forecast those things. I have no reason to doubt CBO’s numbers on this. I haven’t actually looked at that report, but my general experience with them is that it’ s a professional outfit. What does that look like, if that really takes place 10 years down the road. So, you know, first of all, our—the work that we do relates more to the medium term rather than the long term. And so I don’t see this, in particular, as a threat to this business cycle or to the economy this year. It’s more in the longer run, we’ll be spending all of our money on paying interest and not on the t hings that we really need to be doing for future generations and for our own generation. So it’ s a serious problem, but it’ s not a problem that is something that either helps or prevents the Fed from doing our job today. Hi, Chairman. Paul Kiernan from Dow Jones Newswires. I know where the FOMC participants’ estimates for the long-run interest rate are. They’re all above 2½ percent. Right now we’re between 2.25 and 2½. So I think a key question right now is, is policy accommodative at this moment? Are we looking at staying accommodative for some time, or has your estimate of neutral come down, in light of the recent volatility in markets? Thanks. So the range of estimates on the Committee starts at 2½ percent, and th at’s kind of roughly where we currently are. And as I’ve said a couple of times, when you get to that range—you know that we can’t directly observe the neutral rate. We only know it by its works. And so we have to put aside our own priors of what that r ate might be and let the data speak to us. So we can do that. We’re in the range. There are a number of Committee members who are, you know, right around that range. And I think we’re watching to see. We don’ t—I don’t—again, I think that our policy sta nce today is appropriate for the state of the economy. That’s my feeling. We’ re going to be watching data to see whether that’s right, and we’re also going to be watching data to see how these crosscurrents resolve themselves and how the U. economy performs this year. Thank you. Virginie Montet with Agence France-Presse. Among the global developments that the Fed is monitoring, how much of a risk for the American expansion would be the prospect of a“hard” Brexit. So we’ve been monitoring the Brexit situation very carefully for a long time. And for us, that starts with U. financial institutions that have a presence either in the U. or in the EU or both. So we have worked with those institutions alongside U. and EU regulators to assure ourselves that those firms have plans and have liquidity and have all of the things they will need to deal with the full range of Brexit outcomes. So we’ve done a lot of work on that, and, generally speaking—again, a lot of w ork has been done—we have to be humble and say that this is an unprecedented event. But that’s the financial system aspect of it. If there is a hard Brexit, then that would very likely involve disruptions both to the continental economy and certainly to t he U. economy, and we would feel that. The question for us—it wouldn’ t be a huge first-order thing, the economic effects, unless you saw financial disruptions. So, if you saw financial turmoil and that kind of thing, that would be the way it would reach us. I would expect that we would feel some of this, and it’ s very hard to have great confidence that you know what that would be. But it would be something—probably not material to our economy, but it’ s something we’ll be watching very carefully and certainly hoping that there is a resolution short of a hard Brexit. Hi, I’m Jean Yung with Market News. I have a question about the ultimate size of the bala nce sheet. How will the Fed judge what is a reasonable level for financial institution s’ demand for reserves when it appears to be rising at a fast pace over the past year and perhaps at a faster pace than can be explained by regulatory changes during that same time frame? Would you prefer to err on the side of being more generous, or would you try to encourage banks from holding—to hold less reserves. Let me be clear. I don’t know that demand for reserves has risen over the past years. I think our understanding of demand for reserves—remember that the banks have more reserves th an they need. Reserves are still quite abundant. So the question is, how much of that amount is actually going to be needed in the end after, you know, after t he firms adjust to our very gradual decrease? And so our understanding, really, of the distribution of reserves and how much will be needed has moved up over the past year. And then there would be a buffer on top of that. And then we would want to be—we would want to have a buffer, as I mentioned in my remarks, because we want to be operating in an abundant reserves regime where we operate through our administered rates. If you operate too close to that point of scarcity, then you wind up having to have these big, ongoing interventions in the market. We don’ t want the Fed to have a, you know, a large ongoing presence in the market around this. We’d rather just, you know—in managing the federal funds rate, we’d rather have it set by our administered rate s. So that implies you’d want to be a bit above what that equilibrium demand for reserves is. And, again, there’ s no cookbook here, there’s no playbook. No one really knows. The only way you can figure it out is by surveying people and market intelligen ce and then, ultimately, by approaching that point quite carefully. But do you take the survey result s as given, or do you try to encourage banks from holding a. We don’ t take— you know, we don’ t think we have a precise understanding of this at all. I want to be clear about that. These estimates are fairly uncertain. So if you think that the level of demand for reserves is here[gesturing with hands together, in the middle], all you can say is, it’s probably somewhere in this range[gesturing with hands apart, equidistant from the middle]. If banks want to use reserves for a good and sufficient reason— which is to say, to hold liquidity as we require them to do to meet the liquidity coverage ratio, to meet their resolution requirements and resolution planning—we’re not going to discourage them from holding them. They are, in fact, a very safe asset—in a way, the safest asset. And we want the banks to be safe and sound. We didn’ t create the reserv es, you know, with that in mind, but, you know, since—in the post-crisis, you know, regulatory regime, we have brand- new and quite substantial liquidity requirements, which are very good and which have great public benefit. So it’ s not a bad thing that ba nks hold onto these reserves or another safe asset. We don’ t—we’re not encouraging them to hold reserves inste ad of Treasuries. Treasuries or reserves are roughly equivalent for this purpose.. Hi, Mr. Chairman. Courtenay Brown from Axios. A data- dependency question: Has there been a prioritization of market data over the economic data? How do you balance those two things. I would say that, you know, our mandate is maximum employment and stable prices, and that’s about, you know, hard, real-side economic data. We— as I mentioned earlier, we—our tool, you know, our interest rate tool operates on the economy through financial conditions. So financial conditions matter, and they matter in the way that I suggested ear lier—which is to say, broad financial conditions changing over a sustained period—that has implications for the macroeconomy. It does. So if you lower interest rates and they stay low, every borrower in the country ultimately has a lower interest rate. That’ll have an effect on—over time, an effect on the economy. But, again, the entire focus we have is on maximum employment and stable prices, not on any particular financial market or financial conditions generally. Chairman Powell, Myles Udland with Yahoo Finance. I would just ask, I guess, about the balance sheet in general. And are you surprised at how much of a conversation we’re having around the balance sheet, and how much talk about the balance sheet from you rself and various Fed official s have moved financial markets? Because putting out a statement, clarifying your view on the balance sheet, you know, is somewhat surprising, considering it is restating, you know, what the Fed had said all along was the goal with balance sheet normalization—to roll it off, not have it be a key part of policy. And so I would just ask, are you surprised by how far that conversation has gotten just in the last six weeks. You know, I’ll quickly go back—in 2017, we were—in designing the normalization plan, we were concerned at not having two active tools of policy. We learned during the taper tantrum, frankly, in 2013 that was—that would be confusing to markets. So what we did was we set up the normalization of the balance sheet in a way that was very transparent so that you could look and know really, certainly as to Treasuries, pretty much the exact amounts and the timing in which we would be returning these assets to private hands. And we put that out there very publicly and in the hope that it would be priced in and understood, and that then we could put the balance sheet on the side and have inter est rates be the active tool of policy. So that went along that way very well, and I think that division of labor was a good one for our policy and for the benefit of the country. I think that there’s—I think the market is now looking for more clarity around that, and I think we’ll be providing it. That’s what’s happened. Thanks very much.\n",
      "Base Whisper Transcription:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\utils\\reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperX transcription completed in 22.35 seconds\n",
      "WhisperX Transcription:  Good afternoon, everyone, and welcome. I will start with a recap of our discussions, including our assessment of the outlook for the economy and the judgments we made about our interest rate policy and our balance sheet. I will cover the decisions we made today, as well as our ongoing discussions of matters on which we expect to make decisions in coming meetings. My colleagues and I have one overarching goal to sustain the economic expansion with a strong job market and stable prices for the benefit of the American people. The U.S. economy is in a good place and we will continue to use our monetary policy tools to help keep it there. The jobs picture continues to be strong with the unemployment rate near historic lows and with stronger wage gains. Inflation remains near our 2 percent goal. We continue to expect that the American economy will grow at a solid pace in 2019, although likely slower than the very strong pace of 2018. We believe that our current policy stance is appropriate at this time. Despite this positive outlook, over the past few months we have seen some cross currents and conflicting signals about the outlook. Growth has slowed in some major foreign economies, particularly China and Europe. There is elevated uncertainty around several unresolved government policy issues, including Brexit, ongoing trade negotiations, and the effects from the partial government shutdown in the United States. Financial conditions tightened considerably late in 2018 and remain less supportive of growth than they were earlier in 2018. And while most of the incoming domestic economic data have been solid, some surveys of business and consumer sentiment have moved lower, giving reason for caution. We always emphasize that our policies are data dependent. In other words, as economic conditions and the outlook evolve, we take that new information into account in setting our policies. We are now facing a somewhat contradictory picture of generally strong U.S. macroeconomic performance alongside growing evidence of cross currents. At such times, common sense risk management suggests patiently awaiting greater clarity. an approach that has served policymakers well in the past. With that in mind, I'd like to spell out how the Federal Open Market Committee has been thinking about these issues. At our December meeting, we noted the solid outlook for steady growth, vigorous job creation, and price stability. We also stressed that the extent and timing of any rate increases were uncertain and would depend on incoming data and the evolving outlook. We therefore said that we would be paying close attention to global economic and financial developments and assessing their implications for the economic outlook. Today, the FOMC decided that the cumulative effects of those developments over the last several months warrant a patient wait and see approach regarding future policy changes. In particular, our statement today says, in light of global economic and financial developments and muted inflation pressures, the committee will be patient as it determines what future adjustments to the target range for the federal funds rate may be appropriate. This change was not driven by a major shift in the baseline outlook for the economy. Like many forecasters, we still see sustained expansion of economic activity, strong labor market conditions, and inflation near 2 percent as the likeliest case. But the cross-currents I mentioned suggest the risk of a less favorable outlook. In addition, the case for raising rates has weakened somewhat. A traditional case for rate increases is to protect the economy from risks that arise when rates are too low for too long, particularly the risk of too high inflation. Over the past few months, that risk appears to have diminished. Inflation readings have been muted, and the recent drop in oil prices is likely to push headline inflation lower still in coming months. Further, as we noted in our post-meeting statement, While survey-based measures of inflation expectations have been stable, financial market measures of inflation compensation have moved lower. Similarly, the balance, the risk of financial imbalances appears to have receded as a number of indicators that showed elevated levels of financial risk appetite last fall have moved closer to historical norms. In this environment, we believe we can best support the economy by being patient and evaluating the outlook before making any future adjustment to policy. Let me now turn to balance sheet normalization. Over its past three meetings, the FOMC has held in-depth discussions on the final stages of this process. Today, we made some important progress in clarifying the path forward, as summarized in the statement regarding monetary policy implementation and balance sheet normalization that we released with today's FOMC statement. The Committee made the fundamental decision today to continue indefinitely using our current operating procedure for implementing monetary policy. That is, we will continue to use our administered rates to control the policy rate with an ample supply of reserves so that active management of reserves is not required. This is often called a floor system or an abundant reserve system. under the current set of operating procedures, as outlined in the implementation note released today. This means that the federal funds rate, our active policy tool, is held within its target range by appropriately setting the federal reserves' administered rates of interest on reserves, as well as the offer rate on the overnight reverse repo facility without managing the supply of reserves actively. As the minutes of our recent discussions have indicated, the FOMC strongly believes that this approach provides good control of short-term money market rates in a variety of market conditions and effective transmission of those rates to broader financial conditions. Settling this central question clears the way for the FOMC to address a number of further questions regarding the remaining stages of balance sheet normalization. The decision to retain our current operating procedure means that, after allowing for currency and circulation, The ultimate size of our balance sheet will be driven principally by financial institutions' demand for reserves plus a buffer so that fluctuations in reserve demand do not require us to make frequent sizeable market interventions. Estimates of the level of reserve demand are quite uncertain, but we know that this demand in the post-crisis environment is far larger than before. Higher reserve holdings are an important part of the stronger liquidity position that financial institutions must now hold. Moreover, based on surveys and market intelligence, current estimates of reserve demand are considerably higher than estimates of a year or so ago. The implication is that the normalization of the size of the portfolio will be completed sooner and with a larger balance sheet than in previous estimates. In light of these estimates and the substantial progress we've made in reducing reserves, the committee is now evaluating the appropriate timing for the end of balance sheet runoff. This decision will likely be part of a plan for gradually reaching our ultimate balance sheet goals while minimizing risks to achieving our dual mandate objectives and avoiding unnecessary market disruption. We will be finalizing these plans at coming meetings. The process of balance sheet normalization is unprecedented. Throughout this process, we've attempted to lay out our plans well in advance, and we've been willing to make changes as we learn more about the process. The implementation and normalization statement released today is intended to provide some additional clarity regarding the conditions under which we might adjust our plans. The statement makes three points. First, as we've long emphasized, the federal funds rate is our active monetary policy tool. Second, as far as the particular details of normalization are concerned, we will not hesitate to make changes in light of economic and financial developments. This does not mean that we would use the balance sheet as an active tool, but occasional changes could be warranted. Third, we repeat a sentence of the normalization principles we adopted in June of 2017. While the federal funds rate would remain our active tool of policy in a wide range of scenarios, we recognize that the economy could again present conditions in which federal funds rate policy is not sufficient. In those cases, the FOMC would be prepared to use its full range of tools, including balance sheet policy. Times of Economic Uncertainty put a premium on the clarity and predictability of FOMC policy. We are committed to clearly explaining what we are doing and why we're doing it, both regarding the path of rates and also regarding management of the balance sheet. We believe that this transparency is how we can best contribute to macroeconomic stability. Thank you. I'll be glad to take your questions. I'm Howard Schneider with Reuters. So you've said many times recently that policy was still accommodated and then it needn't be so. You've said recently that policy, the state of the policy was still accommodated and that the economy didn't require that anymore. Is that still the case? If so, how do you justify the removal of the need for some further interest rate increases? Basically, are we at neutral now or does the economy still need accommodation? We think that our policy is at the appropriate point right now. We think our policy stance is appropriate right now, we do. We also know that our policy rate is now in the range of the committee's estimates of neutral. So we'll be, again, we think our policy stance is appropriate. And they're long from the Washington Post. Last week, the IMF said risks are clearly skewed to the downside for the U.S. and global economy. Can you clarify, does the FOMC see risks as skewed to the downside, particularly after you removed the statement about risk being balanced? We had an extensive discussion of the baseline and also of the risk to the baseline. And the risks are, of course, the fact that financial conditions have tightened, that global growth has slowed, as well as some, let's say, government-related risks like Brexit. and trade discussions and also the effects and ultimate disposition of the shutdown. So we looked at those and the way we think of it is that policy, we will use our policy and we have to offset risks to the baseline. So we view the baseline as still solid and part of that is the way we adjusted our baseline to address those risks. So that's the way we're thinking about that now. Thanks, Sam Fleming from the Financial Times. The Fed has linked its commitment to patients in part to subdued inflation outcomes. Would you be comfortable with continuing patients, even if they're modest, if transient, overshoots to the inflation target by core inflation? How sensitive are you right now to developments in core inflation when determining the next move? Thanks. Generally speaking, we think the outlook is favorable. And we think that these cross currents that are referred to these risks are going to be with us for a while We think our stance is appropriate We think there's no pressing need to change our policy stance and no need to rush to judgment there I would say that We'll be looking at a full range of data, and that'll include inflation data. It'll include all data relevant to our dual mandate of stable prices and maximum employment. Remember that our inflation objective is a symmetric one, meaning that we're always trying to get to 2%. And we don't look at inflation equally on both sides. So I can't get into specific hypotheticals, but I do believe that we have a symmetric objective, and I believe we'll act that way. Thank you. We learned from the last minutes of the meeting that some of the tweaks you make to the statement have a lot more portent than we thought. In light of that, I wonder if you can provide us with a decoder ring for this statement. Adjustments, does that suggest the next move in interest rates is as likely to be up as down? And when you, in light of global economic and financial developments with muted inflation pressures, does that suggest you have to see both the cessation of these cross currents that you've talked about? and inflation moving up before you get off the dime, so to speak, and move. Sorry, say again what the first question was. First question is adjustments. Is that meant to imply the next move is as most likely to be up as down? Yeah, I'm just going to say that it's going to depend entirely on the data. We're not making a judgment. We don't have a strong prior. We will be we will patiently wait and let the data clarify. Some of the cross currents that I refer to may be with us for a while, and I think we'll be looking at seeing those clear up as they relate to the outlook for the U.S., and that'll be an important aspect as well. Your second question was, Just the cessation of those cross currents, but the end of these muted inflation pressures, are they both sort of things that are necessary for you to change this patient's stance? It's really hard to speak at bad generalities. We'll be looking at everything. But I do think that muted inflation pressures You know, I would want to see a need for further rate increases, and for me, a big part of that would be inflation. It would be the only thing, but it would certainly be important. Mr. Chairman, did the committee discuss an actual change to the runoff policy or the runoff schedule right now? If so, if not, is that under consideration right now? And when might we know? The second thing is I have to nail down this thing. You guys, Fed folks, keep mentioning the market average or the market outlook for the size of the balance sheet. Are you endorsing the market average, which is three and a half trillion? And if you're not endorsing it, why do you keep mentioning it? Okay. Um, so today I'm here to talk about decisions and also discussions about decisions that haven't been made. So with, with, we're talking about the latter thing, which discussions. And so I can't get ahead of where decisions are, but, um, so the committee is what we're looking to do is create a whole plan that will bring us to our goal, our longer-run goal, which is a balance sheet no larger than it needs to be for us to efficiently conduct, efficiently and effectively conduct, conduct monetary policy, but to do so in a way that doesn't put our goals at risk or result in unnecessary market turmoil. So there are a lot of pieces to that, and we've learned over time that It's when making these, when designing these plans, like for example, the original normalization plan, it's good to take your time, let the best ideas rise to the top, let them stand the test of time and argument, and then move when you're really comfortable with what you've got and when you feel you can communicate it clearly. So I don't want to get ahead of that process today. But so we've discussed, there are a number of pieces to that puzzle. There are several different pieces to them, and I think they're coming in very pleased at the progress that we've made. And the piece that you mentioned is something that is in those discussions. That's the first question. I'm not going to give our estimate or ratify anybody else's estimate of what the equilibrium balance sheet is here today. There are estimates out there, but I'm not at a point today where I'm going to be giving out numbers on that. But there are estimates, and I think they're consistent with what I said broadly speaking. So just to clarify, I'm sorry, you did discuss reducing the pace of the runoff. That sounds like what we said today. Yeah, it's so, again, we haven't made any decisions. There are no decisions that have been made, but there are different pieces of the thing, and that is in the discussion. That's one of many pieces that is in the discussion. That was reflected in the last minutes, actually. Thanks, Nick Timmeros of the Wall Street Journal. Chairman Pell, I want to follow up on Steve's question. The size of the balance sheet obviously matters a great deal, but so too if you follow the arguments that were made when the Fed was purchasing these assets, does the duration of those holdings. you are once you reach the terminal level of reserves and you have to reinvest maturing mortgage backed securities into treasuries. It'll matter a great deal of course where along the curve the Fed resumes those reinvestments. And so I wonder what does your staff research show about the degree of accommodation that would be provided by either moving to the front end of the curve and holding over investing perhaps in shorter maturity assets versus the other approach that was identified in the December meeting minutes, which would be to simply reflect issuance of the outstanding treasure maturities. And which approach do you think is more appropriate in the current environment? These are great questions. Let me say that the question of the ultimate composition of our balance sheet in the longer run is a very important one, and it's one that we see ourselves as coming to, you know, fairly soon as in incoming meetings. It won't be the first thing we work on, but it'll be one of the first things that we try to resolve. We've had discussions at one of the last two meetings on this, and we haven't come to a judgment on that. I wouldn't comment beyond saying that we understand that's a key question and there are issues to be decided. There are benefits and costs to taking different approaches and I wouldn't want to prejudge them today. Probably a little bit to understand what has changed since we sat here with you six weeks ago. You've said today that you think that inflation would be the reason that the Fed would need to continue raising rates. Has the inflation outlook shifted that dramatically in the last six weeks? Can you speak specifically to why you've moved from a posture of saying we expect to keep raising rates this year to a posture of standing still? So I point to a couple of things. First, the narrative of slowing global growth. continues, if you will. The incoming data have shown more of that. We've seen that both in China and in Western Europe. And so that's an important – that is important implications for us, and that story has – let's just say it continues. And in addition, I mean, I think important possibly less important now, probably less important now, but has been the shutdown, which will leave some sort of imprint on first quarter GDP. We don't know the ultimate resolution of it. If that's all there is and the shutdown is gone and there isn't another shutdown, then We'll get most of that back in the second period, but second quarter. So those things, in addition, you have to look back. Financial conditions began to tighten in the fourth quarter, and they now have persisted and remain tighter, significantly tighter, let's say, than they were. And that's something that we have to take into account as well. So that's where we are. Michael McKee from Bloomberg Television and Radio. He said, you like to be a playing speaker, so let me try to have you put this as plainly as possible. Is it fair to characterize this as not a pause in a tightening cycle, but the end of the tightening cycle now, a new regime for the Fed? And if not, can you put a time frame on patient? Does patient have some sort of time frame? And I'm wondering about your reaction to the criticism you got on your December 19th news conference, your later statements, do you feel you've put a, how put into the markets? So patients, I think we're going to know in hindsight because the length of this patient period is going to depend entirely on incoming data and its implications for the outlook. So that's going to be, so it's hard to say, you know, it's hard to think of what to call it at this point or how to label it. So really your question, your second question is about how do we think about financial conditions? And I would say this, we think about a broad range of financial conditions, not just one or two things. It's interest rates, it's risk spreads, it's currency, it's the stock market, it's credit availability, it's many, many factors. And what matters for financial conditions is when there are changes, and those changes are sustained for a period of time, then they become important for us because they have important macroeconomic implications. So that's how we think about it. So we don't react to most things that happen in the financial markets. But when we see a sustained change in financial conditions, then that's something that has to play into our thinking. In fact, our policy works through changing financial conditions. So it's sort of the essence of what we do. I just wanted to ask, first of all, about whether the Fed is gathering information about some of the new money laundering information that's come out about Deutsche Bank and Danska Bank and whether you have any concerns there. And then also, I was just wondering if you could say whether there's any kind of timeline on when the Fed might make a decision on real-time payments and whether you're going to build a real-time payment system. Right, so on the first question, I can, obviously, we don't comment on individual investigations or whether they're happening. I will say that we take our enforcement powers very seriously and we put them to work when we feel it's justified. In terms of real-time payments, It's something we're very actively working on, as you obviously know, we have some proposals out and we're considering them. You know, the thing is, it's very important in that space to consult with the full range of market participants and interest groups, consumer groups, and we've done that, as I'm sure you know. over a period of years, we don't have plenary authority to just do things for the most part in the payment space. We've been more of a convener bringing the industry and the public, public interest groups, and all those groups around the table. And I think we've played a constructive role in that respect, and I believe that will continue. Thanks, Jim Pusengara with the LA Times. You and your colleagues may have noticed President Trump for the past six months has been urging the Fed not to raise rates, to stop raising rates. How would you respond to those who would suggest that the Fed just caved to the President's demands? So what we care about, and really the only thing we care about at the Fed, is doing our job for the American people and using our tools appropriately. So that's very strongly our culture. I think anyone who knows the Fed or has worked at the Fed would recognize that description. So we're always going to do what we think is the right thing. We're never going to take political considerations into account or discuss them as part of our work. You know, we're human, we make mistakes, but we're not going to make mistakes of character or integrity. And I would want the public to know that, and I would want them to see that in our actions. Edward Lawrence from Fox Business News. Thank you, Mr. Chairman. The long-term federal funds rate is 2.8 percent. I've talked last year with a number of Fed presidents who worry that under 3 percent is not enough to handle the next recession. You say that's your first tool. It's your primary means of adjusting monetary policy. So with a larger balance sheet, with a larger balance sheet, how could you handle that next recession then with the combination of those two? I guess the sense of your question is that we could be in a situation in the future. We hope not, but we could be in a situation where we'd like to cut rates more than we can, effectively, and we hit the zero lower bound. We don't think anything like that is in the cards now. There's no reason to think that it would be. But as we said in today's release, If that happens, then we'll use the full range of our tools, and that includes the balance sheet. But we would use it after using our conventional tools, which would be the interest rate and forward guidance about the interest rate. Even if you have a large balance sheet, 4 trillion of up 4 trillion? Yes, there would be room to do substantially more. I just wanted to go back to you had mentioned on the cross currents the government shutdown issue. You mentioned a couple of weeks ago that that information would clearly show up in the data. I'm wondering as you guys discussed during this week's meeting. what the potential economic impact would be of the shutdown, the possibility of a second one, whether or not it would diminish consumer confidence, have some severe ripple effects, just talking to other folks outside businesses, clearly they were suffering and seeing a lot of playing, and just wondering about for American families that missed two paychecks, how is this going to play out for them for the months to come? Right, so let me give you the economic side of it first, is that Even with a fairly long shutdown, as long as that's the end of it and everyone gets their back pay, except the contractors, I guess, the private sector contractors, but some people get their back pay than the lost GDP. will be, will be regained in the second quarter. So that's, that's that. I would say that the, you know, we all see the suffering and the heartbreak and all the pain people go through. I see, you know, federal employees doing, doing their work and I'm, you know, really grateful they did. I mean, to be doing, doing your work while you're not getting paid, it's something we should all be grateful for. Did that answer both your questions? So would there be a permanent effect? As I mentioned, there wouldn't be if there isn't another shutdown. If there were going to be a permanent effect or a lasting effect, let's say, it would be from a longer shutdown or perhaps a second shutdown and that would be through the channel of a loss of confidence in our ability to make policy in the United States. That would be the channel of that. And I think that was something that we and many others were worried about as there was talk of an even longer shutdown. In terms of ideas for not having more shutdowns, I know Congress is actually looking at some of those. So I think that could be a profitable thing to explore. Marty Kretsinger AP, the beige book that was prepared for this meeting noted a rising concern among business contacts about a higher trade tariffs and the tensions there. Did that play a part in the discussion and the decision that you made on shifting the wording on your statement? Trade, you sound like you're an avid reader of the beige book, and that's great. The trade, as you will know then, trade has been a big feature in the beige book for some time now. The beige book is a collection of all of the comments that our Reserve Bank presidents get from their district. It's incredibly valuable because you're getting actual reports from people who are on the line. And there have been real concerns about trade right along the line, both in terms of availability of materials and costs and things like retaliation abroad and that kind of thing. So that's been a concern. I would say the longer term concern though is the negotiations that are going on is if they linger then there could be more and more uncertainty and you worry over time that that could have an effect on business confidence. So far the actual amount of tariffs that have been applied both here and in China is not enough to have material effects on GDP either here or in China. So the concern is more a longer drawn, for me, a longer drawn-out set of negotiations back and forth which could result in sapping business confidence. Uncertainty is not the front of business. And then Paul. And Nancy Marshall-Genzur from Marketplace. I want to talk to you about corporate debt. Are you worried that by taking a pause and raising interest rates, we've had low interest rates for so long, are you contributing to a bubble in corporate debt? So we've called out corporate debt as a risk, more of a macroeconomic risk, I think, than a financial stability risk. The sense of that being that if you have companies that are highly levered and we do go into a downturn, they're going to be less able to weather that and keep serving their customers and, you know, may have to do layoffs and things like that, which so they can amplify and affect a negative downturn. So we watch that. We also watch carefully for the exposure of the financial system to these companies. In other words, banks are arranging a lot of these loans. The question is, what is their exposure? Do they retain big pieces of the loans? Do they have obligations to underwrite loans, which build up in a pipeline? So we monitor those risks very carefully. And frankly, the banks monitor them much better with our support and help than they did before the crisis. So it's a concern. It's something that we're watching. Of course, November or December and January were much slower months for those sorts of things. But it'll be something that we're always paying close attention to. Chairman Powell, Greg Robb from MarketWatch. Financial markets have reacted strongly to the decision and the press conference. The Dow Jones industrial average is up more than like 500 points. There's a sense in the market that you've, that there's a new, you know, what people call the Powell put on the markets. Are financial markets wrong in that assessment? You know, I would point to, all the continuity here. The thing we did on the balance sheet is something we've been working on for, frankly, years, the thing we announced today. And so we're providing clarity there. I think that's a constructive thing to do. My, honestly, only motivation is to do the right thing for the economy and for the American people. That's it. And the situation, I think, calls for patience. I think it does. And it's just The stance of policy we think is appropriate We see these uncertainties and we see a time when we can afford to We have the luxury of being able to wait and watch and that's what we're planning to do And I think it's the right thing. I feel strongly that it is Chairman Powell Sorry about that. The Office of the Comptroller of the Currency last year completed its fintech charter. And one of the questions around that charter has been whether the Federal Reserve will allow such a chartered bank to access the payment system. I'm curious if you think a fintech charter is a good idea in general, and what conditions you think might be necessary to allow the Fed to allow such a chartered institution access to the payment system? I'm not going to be able to help you much on that. Those are great questions, and those are questions that are great supervisory people are looking at. I think we're open to these ideas, but I don't have any news for you on that today. Thank you. Steve Beckner, freelance journalist reporting for NPR, Mr. Chairman. You've echoed the widespread concern about slowing growth in China and elsewhere in the world. But I wonder whether it's possible that slower growth abroad might actually be beneficial to this country in some respects, at least. For example, perhaps increasing capital inflows and putting downward pressure on long-term rates in this country has happened in the Asian financial crisis in the late 90s. You know, Steve, it's certainly possible. Ultimately, though, you know, a strong global economy is good for us. We export to these countries. We trade with these countries. I mean, part of the story of 2017, for example, was that European growth kept coming in stronger and stronger, and that meant the euro was strong and that supported our exports. So ultimately, I think we benefit from having strong growth abroad, although you point to an interesting case. Chairman Powell, Mark Hamrick with Bankrate. Thank you. As you probably heard, the Congressional Budget Office is projecting that federal debt is expected to surge to about $29 trillion over the next 10 years, reaching the highest share since the end of World War II. First of all, does that sound like it could be a reasonable forecast with the administration seeming to take plenty of opportunities to question the legitimacy of CBO. And then secondly, what effect does that have on interest rates and the public if indeed that's even close to being true? So first, it is important. We don't do fiscal policy. We don't advise the government or Congress on fiscal policy. So I'll limit myself to more high-level comments and say that it is not a secret, it is a long-known fact that the U.S. federal government budget is on an unsustainable path and that needs to be addressed. And that is driven principally by the combination of health care costs really due to our health care delivery system and the aging of the population. So, and there's no time like now when the economy is healthy, growing, people are working, to go after that problem. Ultimately, we will have to. We don't have a forecast. We don't forecast those things. I have no reason to doubt CBO's numbers on this. I haven't actually looked at that report. But my general experience with them is that it's a professional outfit. So what does that look like if that really takes place 10 years down the road? So first of all, the work that we do relates more to the medium term. rather than the long term. And so I don't see this in particular as a threat to this business cycle or to the economy this year. It's more in the longer run, we'll be spending all of our money on paying interest and not on the things that we really need to be doing for future generations and for our own generation. So it's a serious problem, but it's not a problem that is something that either helps or prevents the Fed from doing our job today. Hi Chairman, Paul Kiernan from Dow Jones News Wires. I know where the FOMC participants' estimates for the long run interest rate are. They're all above 2.5 percent. Right now, we're between 2.25 and 2.5. So, you know, I think a key question right now is, is policy accommodative at this moment? Are we looking at staying accommodative for some time, or has your estimate of neutral come down in light of the recent volatility in markets? Thanks. So the range of estimates on the committee It starts at 2.5 percent, and that's kind of roughly where we currently are. And as I said a couple times, when you get to that range, you know that we can't directly observe the neutral rate. We only know it by its works. And so we have to put aside our own priors of what that rate might be and let the data speak to us. So we can do that. We're in the range. There are a number of committee members who are you know, right around that range, and I think we're watching to see. We don't, and I don't, I don't, I think, again, I think that our policy stance today is appropriate for the state of the economy. That's my feeling. We're going to be watching data to see whether that's right, and we're also going to be watching data to see how these cross currents resolve themselves and how the U.S. economy performs this year. Thank you, Virginie Monte with Agency France Press. Among the global developments that the Fed is monitoring, how much of a risk for the American expansion would be the prospect of a hard Brexit? So we've been monitoring the Brexit. situation very carefully for a long time. And for us, that starts with U.S. financial institutions that have a presence either in the U.K. or in the E.U. or both. So we have worked with those institutions alongside U.K. and E.U. regulators to assure ourselves that those firms have plans and have liquidity and have all the things they will need to deal with the full range of Brexit outcomes. So we've done a lot of work on that. Generally speaking, again, a lot of work has been done. We have to be humble and say that this is an unprecedented event. But that's the financial system aspect of it. If there is a hard Brexit, then that would very likely involve disruptions both to the continental economy and certainly to the UK economy. And we would feel that. The question would, for us, it wouldn't be a huge first order thing, the economic effects, unless you saw financial disruption. So if you saw financial turmoil and that kind of thing, that would be the way it would reach us. I would expect that we would feel some of this. And it's very hard to have great confidence that you know what that would be. But it would be something probably not Probably not material to our economy, but it's something we'll be watching very carefully and certainly hoping that there is a resolution short of a hard Brexit. Hi, Jean Young with Market News. I have a question about the ultimate size of the balance sheet. How will the Fed judge what is a reasonable level for financial institutions' demand for reserves when it appears to be rising at a fast pace over the past year and perhaps at a faster pace than can be explained by regulatory changes during that? same time frame, would you prefer to err on the side of being more generous or would you try to encourage banks to hold less reserves? Let me be clear. I don't know that demand for reserves has risen over the past years. I think our understanding of demand for reserves. Remember that the banks have more reserves than they need. Reserves are still quite abundant. So the question is how much of that amount is actually going to be needed in the end after, you know, after the firm's address to adjust to our very gradual decrease. And so our understanding really of the distribution of reserves and how much will be needed has moved up over the past year. And then there would be a buffer on top of that. And then we would want to be We want to have a buffer, as I mentioned in my remarks, because we want to be operating in abundant reserve regime where we operate through our administered rates. If you operate too close to that point of scarcity, then you wind up having to have these big, ongoing interventions in the market. We don't want the Fed to have a large, ongoing presence in the market around this. in managing the federal funds rate, we'd rather have it set by our administered rates. So that implies you'd want to be a bit above what that equilibrium demand for reserves is. And again, there's no cookbook here. There's no playbook. No one really knows. The only way you can figure it out is by surveying people and market intelligence and then ultimately by approaching that point quite carefully. We don't take this, you know, we don't think we have a precise understanding of this at all. I want to be clear about that. These estimates are fairly uncertain. So if you think that the level of demand for reserves is here, it's probably somewhere, that's all you can say is probably somewhere in this range. If banks want to use reserves for good and sufficient reason, which is to say to hold liquidity as we require them to do, to meet the liquidity coverage ratio, to meet their resolution requirements and resolution planning, We're not going to discourage them from holding them. They are, in fact, a very safe asset in a way the safest asset, and we want the banks to be safe and sound. We didn't create the reserves with that in mind, but since in the post-crisis regulatory regime, We have brand new and quite substantial liquidity requirements, which are very good and which have great public benefit. So it's not a bad thing that banks hold onto these reserves or another safe asset. We're not encouraging them to hold reserves instead of treasuries. Treasuries or reserves are roughly equivalent for this purpose. Hi, Mr. Chairman, Courtney Brown from Axios. A data dependency question. Has there been a prioritization of market data over the economic data? How do you balance those two things? I would say that our mandate is maximum employment in stable prices, and that's about hard, real-side economic data. We, as I mentioned earlier, our tool, our interest rate tool operates on the economy through financial conditions. So financial conditions matter, and they matter in the way that I suggested earlier, which is to say broad financial conditions changing over a sustained period, that has implications for the macroeconomy. It does. So if you lower interest rates and they stay low, every borrower in the country ultimately has a lower interest rate. That will have an effect on, over time, an effect on the economy. But again, the entire focus we have is on maximum employment and stable prices, not on any particular financial market or financial conditions generally. Thanks, Chair Powell-Mazada with Yahoo Finance. I would just ask, I guess, about the balance sheet in general, and are you surprised at how much of a conversation we're having around the balance sheet and how much talk about the balance sheet from yourself and various Fed officials have moved financial markets because putting out a statement, clarifying your view on the balance sheet, It was somewhat surprising considering and just restating what the Fed had said all along was the goal with balance sheet normalization to roll it off, not have it be a key part of policy. And so I would just ask, are you surprised by how far that conversation has gotten just in the last six weeks? You know, I'll quickly go back. In 2017, we were in designing the normalization plan. We were concerned at not having two active tools of policy. We learned during the taper tantrum, frankly, in 2013 that that would be confusing to markets. So what we did was we set up the normalization of the balance sheet in a way that was very transparent so that you could look and know, really, certainly as to treasuries, pretty much the exact amounts and the timing in which we would be returning these assets to private hands. And we put that out there very publicly and in the hope that it would be priced in and understood and that then we could put the balance sheet on the side and have interest rates be the active tool of policy. So that went along that way very well. And I think that division of labor was a good one for our policy and for benefit of the country. I think that there's – I think the market is now looking for more clarity around that, and I think it will be providing it. That's what's happened. Thanks very much. \n",
      " {'wer': 13.554178783664181}\n"
     ]
    }
   ],
   "source": [
    "with open(text_file, \"r\") as file:\n",
    "    true_transcription = file.read().replace(\"\\n\", \" \")\n",
    "\n",
    "print(\"True transcription:\\n\", true_transcription)\n",
    "\n",
    "# Transcribe with base Whisper\n",
    "base_whisper_transcription = transcribe_with_base_whisper(audio_file)[0]\n",
    "print(\"Base Whisper Transcription:\")\n",
    "print(base_whisper_transcription, \"\\n\", compute_metrics([clean_text(base_whisper_transcription)], [clean_text(true_transcription)]))\n",
    "\n",
    "# Transcribe with fine-tuned Whisper\n",
    "fine_tuned_whisper_transcription = transcribe_with_fine_tuned_whisper(audio_file)[0]\n",
    "print(\"Fine-Tuned Whisper Transcription:\")\n",
    "print(fine_tuned_whisper_transcription, \"\\n\", compute_metrics([clean_text(fine_tuned_whisper_transcription)], [clean_text(true_transcription)]))\n",
    "\n",
    "# Transcribe with WhisperX\n",
    "whisperx_transcription = transcribe_with_whisperx_model(audio_file)[0]\n",
    "print(\"WhisperX Transcription:\", \"\".join([i[\"text\"] for i in whisperx_transcription]), \"\\n\", compute_metrics([clean_text(\"\".join([i[\"text\"] for i in whisperx_transcription]))], [clean_text(true_transcription)]))\n",
    "\n",
    "# Transcribe with fine-tuned WhisperX\n",
    "#fine_tuned_whisperx_transcription = transcribe_with_fine_tuned_whisperx(audio_file)\n",
    "#print(\"Fine-Tuned WhisperX Transcription:\", \"\".join([i[\"text\"] for i in fine_tuned_whisperx_transcription]), \"\\n\", compute_metrics(clean_text(\"\".join([i[\"text\"] for i in fine_tuned_whisperx_transcription])), clean_text(true_transcription)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on random short audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_audio_dir = \"data/split_audio\"\n",
    "short_text_dir = \"data/split_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcription:\n",
      " a broad expectation certainly not the depression forecast \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\whisperx\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.80 seconds\n",
      "Base Whisper Transcription:\n",
      " a broad expectation, certainly not the depression forecast.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.88 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "a broad expectation certainly not the depression forecast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "WhisperX Transcription:\n",
      "  A broad expectation, certainly not the depression forecast.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.92 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " and it's it's meant to create a broad sense that we want inflation to average 2 percent over time \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.00 seconds\n",
      "Base Whisper Transcription:\n",
      " And it's meant to create a broad sense that we want inflation to average 2% over time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.18 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and it's meant to create a broad sense that we want inflation to average 2 percent over time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.35 seconds\n",
      "WhisperX Transcription:\n",
      "  And it's meant to create a broad sense that we want inflation to average 2% over time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "Original Transcription:\n",
      " you know we when china's economy slows down we do feel that \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.71 seconds\n",
      "Base Whisper Transcription:\n",
      " you know, when China's economy slows down, we do feel that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.99 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "you know we when china's economy slows down we do feel that\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "WhisperX Transcription:\n",
      "  When China's economy slows down, we do feel that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.34 seconds\n",
      "Original Transcription:\n",
      " you know the the demographics are people are getting older and that should have a secular \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.70 seconds\n",
      "Base Whisper Transcription:\n",
      " You know the demographics are people are getting older and that should have a secular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.24 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "you know the demographics are people are getting older and that should have a secular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  You know the demographics are people are getting older and that should have a secular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "Original Transcription:\n",
      " domestic policy advisor at the white house \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.53 seconds\n",
      "Base Whisper Transcription:\n",
      " domestic policy advisor at the White House.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.54 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "dynastic policy advisor the winehouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.29 seconds\n",
      "WhisperX Transcription:\n",
      "  domestic policy advisor at the White House.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.55 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.18 seconds\n",
      "Original Transcription:\n",
      " the shorter term inflation expectation measures particularly the surveys \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.44 seconds\n",
      "Base Whisper Transcription:\n",
      " the shorter term inflation expectation measures, particularly the surveys.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.56 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "the shorter term inflation expectation measures particularly the surveys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "WhisperX Transcription:\n",
      "  the shorter term inflation expectation measures, particularly the surveys.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " do you think elected officials should consider in \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.23 seconds\n",
      "Base Whisper Transcription:\n",
      " that you discuss at your meeting today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.49 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "did you discuss at your meeting today\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.33 seconds\n",
      "WhisperX Transcription:\n",
      "  that you discuss at your meeting today.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.41 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "Original Transcription:\n",
      " right in our discussions the last couple of days \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.39 seconds\n",
      "Base Whisper Transcription:\n",
      " right in our discussions the last couple of days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.50 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "write in our discussions the last couple of days\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.34 seconds\n",
      "WhisperX Transcription:\n",
      "  right in our discussions the last couple of days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.52 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.55 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "Original Transcription:\n",
      " and have moved into a range that appears broadly consistent with our longer run inflation goal of 2 percent \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.42 seconds\n",
      "Base Whisper Transcription:\n",
      " and have moved into a range that appears broadly consistent with our longer-run inflation goal of 2%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.40 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and have moved into a range that appears broadly consistent with our longer run inflation goal of 2 percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.28 seconds\n",
      "WhisperX Transcription:\n",
      "  and have moved into a range that appears broadly consistent with our longer-run inflation goal of 2%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.28 seconds\n",
      "Original Transcription:\n",
      " under 13 3 what type of assets are you allowed to buy could you buy \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.70 seconds\n",
      "Base Whisper Transcription:\n",
      " under 13 three. What type of assets are you allowed to buy? Could you buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.31 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "under 13 3 what type of assets are you allowed to buy could you buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.33 seconds\n",
      "WhisperX Transcription:\n",
      "  under 13. What type of assets are you allowed to buy? Could you buy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "Original Transcription:\n",
      " changes that's the most recent set of ones that we've done and again we hope \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.81 seconds\n",
      "Base Whisper Transcription:\n",
      " changes that's the most recent set of ones that we've done and again we hope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.86 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "changes that's the most recent set of ones that we've done and again we hope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.34 seconds\n",
      "WhisperX Transcription:\n",
      "  changes, that's the most recent set of ones that we've done. And again, we hope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "Original Transcription:\n",
      " by helping them make it through this very difficult time \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.59 seconds\n",
      "Base Whisper Transcription:\n",
      " by helping them make it through this very difficult time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.76 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "by helping them make it through this very difficult time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "WhisperX Transcription:\n",
      "  by helping them make it through this very difficult time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.92 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " wonder if you can put some detail on that how much concern do you have in terms of \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.62 seconds\n",
      "Base Whisper Transcription:\n",
      " detail on that. How much concern do you have in terms of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.83 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "detail on that how much concern do you have in terms of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  detail on that how much concern do you have in terms of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "Original Transcription:\n",
      " cases hospitalizations and deaths and that's great \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.54 seconds\n",
      "Base Whisper Transcription:\n",
      " cases, hospitalizations and deaths. And that's great.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.56 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "cases hospitalizations and deaths and that's great\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "WhisperX Transcription:\n",
      "  cases, hospitalizations, and deaths. And that's great.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "Original Transcription:\n",
      " so and i also thought that you know the he's raising some very interesting questions about \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.96 seconds\n",
      "Base Whisper Transcription:\n",
      " So, and I also thought that, you know, he's raising some very interesting questions about\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.90 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "so and i also thought that you know he's raising some very interesting questions about\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  So, and I also thought that he's raising some very interesting questions about...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.68 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.35 seconds\n",
      "Original Transcription:\n",
      " which had dropped very sharply when the pandemic arrived and then moved back up sharply they look like they may be softening again now \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.03 seconds\n",
      "Base Whisper Transcription:\n",
      " which had dropped very sharply when the pandemic arrived in and moved back up sharply. They look like they may be softening again now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.36 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "which had dropped very sharply when the pandemic arrived and then moved back up sharply they look like they may be softening again now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.31 seconds\n",
      "WhisperX Transcription:\n",
      "  which had dropped very sharply when the pandemic arrived and then moved back up sharply. They look like they may be softening again now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.60 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "Original Transcription:\n",
      " and motor vehicle sales have still been data are pointing \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.96 seconds\n",
      "Base Whisper Transcription:\n",
      " and motor vehicle stales have still been strong nonetheless on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.38 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and motor vehicle stales have still been strong nonetheless on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "WhisperX Transcription:\n",
      "  and motor vehicle stales have still been strong. Nonetheless, on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.92 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "Original Transcription:\n",
      " and the idea was was to make it challenging and put hurdles in place \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.82 seconds\n",
      "Base Whisper Transcription:\n",
      " And the idea was to make it challenging and put hurdles in place.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.19 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and the idea was to make it challenging and put hurdles in place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  And the idea was to make it challenging and put hurdles in place.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.33 seconds\n",
      "Original Transcription:\n",
      " and have helped to restore the flow of credit from private lenders through normal channels \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.70 seconds\n",
      "Base Whisper Transcription:\n",
      " and have helped to restore the flow of credit from private lenders through normal channels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.10 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and have helped to restore the flow of credit from private lenders through normal channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.24 seconds\n",
      "WhisperX Transcription:\n",
      "  and have helped to restore the flow of credit from private lenders through normal channels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "Original Transcription:\n",
      " i would say that before the pandemic \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.80 seconds\n",
      "Base Whisper Transcription:\n",
      " And I would say that before the pandemic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.72 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and i would say that before the pandemic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "WhisperX Transcription:\n",
      "  And I would say that before the pandemic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " so i guess the first thing to say is that the the sep \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.64 seconds\n",
      "Base Whisper Transcription:\n",
      " So I guess the first thing to say is that the the SCP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.87 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "so i guess the first thing to say is that the the scp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  So I guess the first thing to say is that the the SCP.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.52 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "Original Transcription:\n",
      " the test was a substantial improvement in the outlook for the labor market well what does that mean well it means \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.25 seconds\n",
      "Base Whisper Transcription:\n",
      " The test was a substantial improvement in the outlook for the labor market. But what does that mean? Well, it means...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.28 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "the test was a substantial improvement in the outlook for the labor market but what does that mean well it means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.28 seconds\n",
      "WhisperX Transcription:\n",
      "  The test was a substantial improvement in the outlook for the labor market. What does that mean?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "Original Transcription:\n",
      " and many many people go back to work \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.08 seconds\n",
      "Base Whisper Transcription:\n",
      " and many, many people go back to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.11 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and many many people go back to work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.30 seconds\n",
      "WhisperX Transcription:\n",
      "  and many, many people go back to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.68 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " they they had withdrawn a lot of money and and that we've had many weeks of consecutive i believe of of inflows there \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.07 seconds\n",
      "Base Whisper Transcription:\n",
      " They had withdrawn a lot of money and we've had many weeks consecutively, I believe, of inflows there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.36 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "they had withdrawn a lot of money and that we've had many weeks in consecutive i believe of inflows there\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.29 seconds\n",
      "WhisperX Transcription:\n",
      "  They had withdrawn a lot of money, and we've had many weeks consecutively, I believe, of inflows there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.35 seconds\n",
      "Original Transcription:\n",
      " 'd be remiss in not stressing this \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.52 seconds\n",
      "Base Whisper Transcription:\n",
      " I'd be remiss in not stressing this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.74 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "i'd be remiss in not stressing this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "WhisperX Transcription:\n",
      "  I'd be remiss in not stressing this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "Original Transcription:\n",
      " significant support for economic activity and hiring \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.72 seconds\n",
      "Base Whisper Transcription:\n",
      " significant support for economic activity and hiring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.68 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "significant support for economic activity and hiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "WhisperX Transcription:\n",
      "  significant support for economic activity and hiring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.56 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "Original Transcription:\n",
      " low for so long and targeting the markets after the great financial crisis \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.61 seconds\n",
      "Base Whisper Transcription:\n",
      " low for so long and targeting the markets after the great financial crisis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.78 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "low for so long and targeting the markets after the great financial crisis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.33 seconds\n",
      "WhisperX Transcription:\n",
      "  low for so long and targeting the markets after the great financial crisis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "Original Transcription:\n",
      " little support for the idea of tapering mbs earlier \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.37 seconds\n",
      "Base Whisper Transcription:\n",
      " little support for the idea of tapering MBS earlier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.86 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "little support for the idea of tapering nbs earlier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  little support for the idea of tapering MBS earlier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.41 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "Original Transcription:\n",
      " have that done either someplace else or \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.34 seconds\n",
      "Base Whisper Transcription:\n",
      " have that done either someplace else or\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.55 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "have that done either someplace else or\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "WhisperX Transcription:\n",
      "  have that done either someplace else or\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.47 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.19 seconds\n",
      "Original Transcription:\n",
      " at all other than just to say that it's a good time to take a step back and let the institutions of our democracy \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.35 seconds\n",
      "Base Whisper Transcription:\n",
      " at all, other than just to say that it's a good time to take a step back and let the institutions of our democracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.42 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "at all other than just to say that it's a good time to take a step back and let the institutions of our democracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.30 seconds\n",
      "WhisperX Transcription:\n",
      "  at all other than just to say that it's a good time to take a step back and let the institutions of our democracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.43 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.29 seconds\n",
      "Original Transcription:\n",
      " leverage requirements are are are binding it does skew incentives for firms to substitute lower risk assets for high risk \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.40 seconds\n",
      "Base Whisper Transcription:\n",
      " ceasing to be the intended backstop for our big firms that we want it to be. So we do think it's appropriate to consider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.97 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "seizing to be the intended backstop that for our big firms that we want it to be so we do think it's appropriate to consider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.31 seconds\n",
      "WhisperX Transcription:\n",
      "  ceasing to be the intended backstop for our big firms that we want it to be. So we do think it's appropriate to consider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "Original Transcription:\n",
      " the harder it gets i think and we've probably all seen this in our lives the harder it is to get back into the workforce \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.35 seconds\n",
      "Base Whisper Transcription:\n",
      " the harder it gets, I think, and we've probably all seen this in our lives, harder it is to get back into the workforce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.44 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "the harder it gets i think and we've probably all seen this in our lives harder it is to get back into the workforce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.33 seconds\n",
      "WhisperX Transcription:\n",
      "  the harder it gets, I think, and we've probably all seen this in our lives, harder it is to get back into the workforce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.48 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.36 seconds\n",
      "Original Transcription:\n",
      " recent labor market indicators point to a slowing in job growth particularly among smaller businesses \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.03 seconds\n",
      "Base Whisper Transcription:\n",
      " recent labor market indicators point to a slowing in job growth, particularly in smaller businesses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.54 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "recent labor market indicators point to a slowing in job growth particularly among smaller businesses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.40 seconds\n",
      "WhisperX Transcription:\n",
      "  recent labor market indicators point to a slowing in job growth, particularly in smaller businesses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "Original Transcription:\n",
      " get to the numbers that the experts say are required to get to herd immunity \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.60 seconds\n",
      "Base Whisper Transcription:\n",
      " to get to the numbers that the experts say are required to get to herd immunity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.94 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "to get to the numbers that the experts say are required to get to herd immunity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "WhisperX Transcription:\n",
      "  to get to the numbers that the experts say are required to get to herd immunity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.34 seconds\n",
      "Original Transcription:\n",
      " we have two mandates maximum employment and price stability price stability for us means \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.02 seconds\n",
      "Base Whisper Transcription:\n",
      " You know, we have two mandates, maximum employment and price stability. Price stability for us means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 7.18 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "you know we have two mandates maximum employment and price stability price stability for us means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  You know, we have two mandates, maximum employment and price stability. Price stability for us means.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.92 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "Original Transcription:\n",
      " you know things happen with in the factory environment \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.31 seconds\n",
      "Base Whisper Transcription:\n",
      " You know, things happen in the factory environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.05 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "you know things happen with in the factory environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.30 seconds\n",
      "WhisperX Transcription:\n",
      "  You know, things happen in the factory environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "Original Transcription:\n",
      " i want to acknowledge the tragic events that have again \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.99 seconds\n",
      "Base Whisper Transcription:\n",
      " I want to acknowledge the tragic events that have again...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.95 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "i want to acknowledge the tragic events that have again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  I want to acknowledge the tragic events that have again...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.52 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " we're seeing upward upward pressure on prices that's not really what we're seeing \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.15 seconds\n",
      "Base Whisper Transcription:\n",
      " we're seeing upward pressure on prices. That's not really what we're seeing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.04 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "we're seeing upward pressure on prices that's not really what we're seeing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "WhisperX Transcription:\n",
      "  we're seeing upward pressure on prices. That's not really what we're seeing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.36 seconds\n",
      "Original Transcription:\n",
      " but we're just not going to be able to get that last \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.92 seconds\n",
      "Base Whisper Transcription:\n",
      " but we're just not gonna be able to get that last.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.08 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "but we're just not going to be able to get that last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  But we're just not going to be able to get that last.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.24 seconds\n",
      "Original Transcription:\n",
      " their debt loads even in weak periods because rates are rates are quite low your interest payments are low \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.01 seconds\n",
      "Base Whisper Transcription:\n",
      " their debt loads even in weak periods because rates are quite low. Your interest payments are low.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.25 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "their debt loads even in weak periods because rates are rates are quite low your interest payments are low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.26 seconds\n",
      "WhisperX Transcription:\n",
      "  their debt loads even in weak periods because rates are quite low. Your interest payments are low.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "Original Transcription:\n",
      " regain their economic activity i think trying to be really precise about when that might happen and what the numbers might look like is \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.30 seconds\n",
      "Base Whisper Transcription:\n",
      " and regain their economic activity. I think trying to be really precise about when that might happen and what the numbers might look like is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.56 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and regain their economic activity i think trying to be really precise about when that might happen and what the numbers might look like is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "WhisperX Transcription:\n",
      "  and regain their economic activity. I think trying to be really precise about when that might happen and what the numbers might look like is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "Original Transcription:\n",
      " and we think it's very likely to remain low for some time below our target so really it's about \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.33 seconds\n",
      "Base Whisper Transcription:\n",
      " And we think it's very likely to remain low for some time below our target. So really it's about.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.16 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and we think it's very likely to remain low for some time below our target so really it's about\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.38 seconds\n",
      "WhisperX Transcription:\n",
      "  And we think it's very likely to remain low for some time below our target. So really it's about.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.26 seconds\n",
      "Original Transcription:\n",
      " the course of the economy depends on the path of the virus is this \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.96 seconds\n",
      "Base Whisper Transcription:\n",
      " the course of the economy depends on the path of the virus. Is this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.06 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "the course of the economy depends on the path of the virus is this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "WhisperX Transcription:\n",
      "  The course of the economy depends on the path of the virus. Is this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "Original Transcription:\n",
      " moderately above 2 percent for some time we have not adopted a formula \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.02 seconds\n",
      "Base Whisper Transcription:\n",
      " moderately above 2% for some time. We have not adopted a formula.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.15 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "moderately above 2 percent for some time we have not adopted a formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  moderately above 2% for some time. We have not adopted a formula.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.92 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.24 seconds\n",
      "Original Transcription:\n",
      " are going to be challenged really to \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.51 seconds\n",
      "Base Whisper Transcription:\n",
      " are going to be challenged really to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.13 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "are going to be challenged really to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "WhisperX Transcription:\n",
      "  are going to be challenged really to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.29 seconds\n",
      "Original Transcription:\n",
      " keep the fed funds rate in the range you're looking for but \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.46 seconds\n",
      "Base Whisper Transcription:\n",
      " keep the Fed funds rate in the range you're looking for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.73 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "keep the fed funds rate in the range you're looking for but\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "WhisperX Transcription:\n",
      "  keep the Fed funds rate in the range you're looking for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.48 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "Original Transcription:\n",
      " is this the effective end in your view of the pandemic as a constraint on economic activity even though it's still cited as a risk \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.29 seconds\n",
      "Base Whisper Transcription:\n",
      " Is this the effective end in your view of the pandemic as a constraint on economic activity, even though it's still cited as a risk?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.85 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "is this the effective end in your view of the pandemic as a constraint on economic activity even though it's still cited as a risk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.31 seconds\n",
      "WhisperX Transcription:\n",
      "  Is this the effective end in your view of the pandemic as a constraint on economic activity, even though it's still cited as a risk?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.58 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.31 seconds\n",
      "Original Transcription:\n",
      " could actually be quite low going forward but that's not that's not really where our focus is right now \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.81 seconds\n",
      "Base Whisper Transcription:\n",
      " these high inflation readings that we're seeing now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.78 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "these high inflation readings that we're seeing now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  these high inflation readings that we're seeing now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "Original Transcription:\n",
      " how worried are you about transatlantic economic divergence \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.63 seconds\n",
      "Base Whisper Transcription:\n",
      " How worried are you about transatlantic economic divergence?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.66 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "how worried are you about transatlantic economic divergence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "WhisperX Transcription:\n",
      "  How worried are you about transatlantic economic divergence?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.47 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "Original Transcription:\n",
      " and to provide a bit of relief then to support the recovery and hopefully we'll be able to do the third thing which is to avoid longer run damage to the \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.27 seconds\n",
      "Base Whisper Transcription:\n",
      " and to provide a bit of relief then to support the recovery and hopefully we'll be able to do the third thing which is to avoid longer run damage to the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.56 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and to provide a bit of relief then to support the recovery and hopefully we'll be able to do the third thing which is to avoid longer run damage to the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.39 seconds\n",
      "WhisperX Transcription:\n",
      "  and to provide a bit of relief then to support the recovery and hopefully we'll be able to do the third thing which is to avoid longer run damage to the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.42 seconds\n",
      "Original Transcription:\n",
      " and then they were a big part of of creating accommodative financial conditions to support demand \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.87 seconds\n",
      "Base Whisper Transcription:\n",
      " And then they were a big part of creating accommodative financial conditions to support demand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.48 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and then they were a big part of creating accommodative financial conditions to support demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "WhisperX Transcription:\n",
      "  And then they were a big part of creating accommodative financial conditions to support demand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.30 seconds\n",
      "Original Transcription:\n",
      " innovation is fantastic our economy runs on innovation \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.61 seconds\n",
      "Base Whisper Transcription:\n",
      " Innovation is fantastic. Our economy runs on innovation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.97 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "innovation is fantastic our economy runs on innovation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.31 seconds\n",
      "WhisperX Transcription:\n",
      "  Innovation is fantastic. Our economy runs on innovation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.59 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.25 seconds\n",
      "Original Transcription:\n",
      " the course of the economy depends on the path of the virus is this \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.96 seconds\n",
      "Base Whisper Transcription:\n",
      " the course of the economy depends on the path of the virus. Is this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.91 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "the course of the economy depends on the path of the virus is this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  The course of the economy depends on the path of the virus. Is this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "Original Transcription:\n",
      " all of it goes into thinking about monetary policy you mentioned inequality \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.92 seconds\n",
      "Base Whisper Transcription:\n",
      " all of it goes into thinking about monetary policy. You mentioned inequality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.77 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "all of it goes into thinking about monetary policy you mentioned inequality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "WhisperX Transcription:\n",
      "  All of it goes into thinking about monetary policy. You mentioned inequality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.27 seconds\n",
      "Original Transcription:\n",
      " some of you are now being reported as out of the labor force but i you know i would i would more look at those people as unemployed if you add those back \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.49 seconds\n",
      "Base Whisper Transcription:\n",
      " Some of you are now being reported as out of the labor force, but I would more look at those people as unemployed. If you add those back.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.46 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "some of you are now being reported as out of the labor force but you know i would more look at those people as unemployed if you add those back\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.39 seconds\n",
      "WhisperX Transcription:\n",
      "  Some of you are now being reported as out of the labor force, but I would more look at those people as unemployed if you add those back.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.38 seconds\n",
      "Original Transcription:\n",
      " leading to more rapid gains in employment \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.53 seconds\n",
      "Base Whisper Transcription:\n",
      " leading to more rapid gains in employment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.52 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "leading to more rapid gains in employment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.23 seconds\n",
      "WhisperX Transcription:\n",
      "  leading to more rapid gains in employment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "Original Transcription:\n",
      " with our colleagues at the treasury department \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.57 seconds\n",
      "Base Whisper Transcription:\n",
      " with our colleagues at the Treasury Department.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.73 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "with our colleagues at the treasury department\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.22 seconds\n",
      "WhisperX Transcription:\n",
      "  with our colleagues at the Treasury Department.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.95 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "Original Transcription:\n",
      " generally show the public how how our objective function works how we think about the future it isn't meant to actually \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.96 seconds\n",
      "Base Whisper Transcription:\n",
      " generally show the public how our objective function works, how we think about the future. It isn't meant to actually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.14 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "generally show the public how our objective function works how we think about the future it isn't meant to actually\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.68 seconds\n",
      "WhisperX Transcription:\n",
      "  generally show the public how our objective function works, how we think about the future. It isn't meant to actually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.86 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.28 seconds\n",
      "Original Transcription:\n",
      " hello chair powell this is matthew boesler with bloomberg news i wanted to ask you about regulatory forbearance there were some piecemeal \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.30 seconds\n",
      "Base Whisper Transcription:\n",
      " Hello, chair, Paul, this is Matthew Boussler with Bloomberg News. I want to ask you about regulatory forbearance. There was some piecemeal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.62 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "hello chair powell this is matthew bosler with bloomberg news i wanted to ask you about regulatory forbearance there were some piecemeal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "WhisperX Transcription:\n",
      "  Hello, Chair Powell. This is Matthew Boesler with Bloomberg News. I wanted to ask you about regulatory forbearance. There was some piecemeal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 7.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.32 seconds\n",
      "Original Transcription:\n",
      " going into investments maybe in the stock market that aren't so great for them \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.59 seconds\n",
      "Base Whisper Transcription:\n",
      " going into investments maybe in the stock market that aren't so great for them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.02 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "going into investments maybe in the stock market that aren't so great for them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.24 seconds\n",
      "WhisperX Transcription:\n",
      "  going into investments, maybe in the stock market, but aren't so great for them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 6.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.26 seconds\n",
      "Original Transcription:\n",
      " and minimized at this point are we \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 6.28 seconds\n",
      "Base Whisper Transcription:\n",
      " and minimized at this point are we.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.99 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "and minimized at this point are we\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.21 seconds\n",
      "WhisperX Transcription:\n",
      "  and minimized at this point are we.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 5.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 5.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.20 seconds\n",
      "Original Transcription:\n",
      " some are getting through this based on what they've saved and the jobs that they have others are really struggling to get by and i wonder what role what additional role the fed could have in sort of bridging that that yawning gap \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 7.29 seconds\n",
      "Base Whisper Transcription:\n",
      " Some are getting through this based on what they've saved and the jobs that they have. Others are really struggling to get by. And I wonder what role, what additional role the Fed could have in bridging that yawning gap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 8.44 seconds\n",
      "Fine-Tuned Whisper Transcription:\n",
      "some are getting through this based on what they've saved and the jobs that they have others are really struggling to get by and i wonder what role what additional role the fed could have in bridging that yawning gap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.48 seconds\n",
      "WhisperX Transcription:\n",
      "  Some are getting through this based on what they've saved and the jobs that they have. Others are really struggling to get by. And I wonder what role, what additional role the Fed could have in bridging that yawning gap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with base Whisper model...\n",
      "Base Whisper transcription completed in 9.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing with fine-tuned Whisper model...\n",
      "Fine-tuned Whisper transcription completed in 7.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Artem Shkabruk\\.cache\\torch\\whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing with WhisperX model...\n",
      "WhisperX transcription completed in 0.44 seconds\n"
     ]
    }
   ],
   "source": [
    "num = 100\n",
    "\n",
    "wer_rate_base = []\n",
    "wer_rate_finetuned = []\n",
    "wer_rate_whisperx = []\n",
    "\n",
    "time_base = []\n",
    "time_finetuned = []\n",
    "time_whisperx = []\n",
    "\n",
    "for i in range(num):\n",
    "    random_wav = random.choice(os.listdir(short_audio_dir)[5001:]) # since model has been trained on first 5000 files\n",
    "    random_wav_path = os.path.join(short_audio_dir, random_wav)\n",
    "\n",
    "    # Print the corresponding text file content for manual inspection\n",
    "    with open(os.path.join(short_text_dir, random_wav[:-4] + \".txt\"), \"r\") as txt:\n",
    "        original_transcription = txt.read()\n",
    "        \n",
    "        original_transcription = clean_text(original_transcription)\n",
    "        if len(original_transcription.split(\" \")) < 7: # only transcribe files with more than 7 words\n",
    "            continue\n",
    "        \n",
    "        print(\"Original Transcription:\\n\", original_transcription, \"\\n\")\n",
    "\n",
    "        # Transcribe with base Whisper\n",
    "        base_whisper_transcription = transcribe_with_base_whisper(random_wav_path)[0]\n",
    "        print(\"Base Whisper Transcription:\")\n",
    "        print(base_whisper_transcription)\n",
    "\n",
    "        # Transcribe with fine-tuned Whisper\n",
    "        fine_tuned_whisper_transcription = transcribe_with_fine_tuned_whisper(random_wav_path)[0]\n",
    "        print(\"Fine-Tuned Whisper Transcription:\")\n",
    "        print(fine_tuned_whisper_transcription)\n",
    "\n",
    "        # Transcribe with WhisperX\n",
    "        whisperx_transcription = transcribe_with_whisperx_model(random_wav_path)[0]\n",
    "        whisperx_transcription = \"\".join([i[\"text\"] for i in whisperx_transcription])\n",
    "        print(\"WhisperX Transcription:\\n\", whisperx_transcription)\n",
    "\n",
    "        # Transcribe with fine-tuned WhisperX\n",
    "        #fine_tuned_whisperx_transcription = transcribe_with_fine_tuned_whisperx(random_wav_path)\n",
    "        #print(\"Fine-Tuned WhisperX Transcription:\", \"\".join([i[\"text\"] for i in fine_tuned_whisperx_transcription]))\n",
    "\n",
    "        wer_rate_base.append(compute_metrics([clean_text(base_whisper_transcription)], [clean_text(original_transcription)])[\"wer\"])\n",
    "        wer_rate_finetuned.append(compute_metrics([clean_text(fine_tuned_whisper_transcription)], [clean_text(original_transcription)])[\"wer\"])\n",
    "        wer_rate_whisperx.append(compute_metrics([clean_text(whisperx_transcription)], [clean_text(original_transcription)])[\"wer\"])\n",
    "\n",
    "        time_base.append(transcribe_with_base_whisper(random_wav_path)[1])\n",
    "        time_finetuned.append(transcribe_with_fine_tuned_whisper(random_wav_path)[1])\n",
    "        time_whisperx.append(transcribe_with_whisperx_model(random_wav_path)[1])\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.73553398188583\n",
      "9.785396501780761\n",
      "18.025972933615108\n",
      "5.895717124785146\n",
      "6.124618218791101\n",
      "0.26086540375986406\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.mean(wer_rate_base))\n",
    "print(np.mean(wer_rate_finetuned))\n",
    "print(np.mean(wer_rate_whisperx))\n",
    "\n",
    "print(np.mean(time_base))\n",
    "print(np.mean(time_finetuned))\n",
    "print(np.mean(time_whisperx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
